<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>_非结构稀疏.md</title>
    <url>/project/2022/04/09/%E9%9D%9E%E7%BB%93%E6%9E%84%E7%A8%80%E7%96%8F/</url>
    <content><![CDATA[<p>#Deep Neural Networks<br><img src="https://raw.githubusercontent.com/HURONG0510/blogpic/main/20220409/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20220409221424.7c2prqkmli80.png" alt="神经网络简单举例"></p>
<p>ANN是一类执行分类、拟合和其它数据分析任务的模型。他们是由一系列的layer组成，每个layer在输入向量上执行线性或赋形变化，然后在生成的向量上应用非线性函数，称为激活函数。数据依次遍历这些层得到最终结果。执行其它功能的layer也可能出现在网络中，包含降低数据维度的pooling layer，提高网络对从未见过的数据性能的regularization layer。<br>神经网络中的数据和变化通常表示为tensor。网络在训练期间设置的值称为parameters或weights，将向网络呈现数据和更新参数的单一步骤称为一个training iteration。对所有训练数据集执行示例过程，直到网络得到充分训练，每次对整个训练数据集进行网络训练时，都被称为一个epoch。一个神经网络通常被训练上十或上百次。在训练过程中控制网络训练或操作但未被修改的值被称为hyperparameters.一旦网络被训练完成，参数就固定，模型可以用来分析新数据，这个过程称为inference。</p>
<p>最简单的神经网络layer是dense或fully-connected layer。密集层输入长度为$N$的向量$x$,产生长度为$M$的向量$y$，其参数由权重矩阵$W\in R^{M\times N}$，他的实现函数为$$y&#x3D;f(Wx+b)$$其中$f()$是activation function。深度神经网络在输入和输出之间具有许多层，使它们能够学习非常复杂的函数，并减少或消除对特征提取的需求。与其他统计模型相比，DNN 具有非常多的参数，通常从数十万到数亿个参数不等。</p>
<p>现代DNN在根据其训练数据进行评估时通常可以达到非常高的准确性，但在未知数据集上获得类似性能可能会很大难度。已经开发了很多方法来改善未知数据集的模型性能，有时以降低训练数据的性能为代价，这些方法称为regularization。它们包括对训练过程的修改、对优化器目标的修改以及神经网络中的其他层，例如 dropout和batch normalization层。 </p>
<h1 id="Neural-Network-Pruning"><a href="#Neural-Network-Pruning" class="headerlink" title="Neural Network Pruning"></a>Neural Network Pruning</h1><p>DNN中的大量参数使他们在实践中难以应用。neural network pruning属于最后一类。修剪方法是用于训练神经网络或调整已经训练过的网络的技术，以便其大量参数变为零。这样做的方式是尽量减少修剪导致的推理准确性的降低。如果我们将每个参数视为表示线性变换中输入和输出之间的连接，则可以将修剪视为删除这些连接。如下所示，pruning fraction或pruning rate是图层或网络中被修剪的connected fraction。<br><img src="https://raw.githubusercontent.com/HURONG0510/blogpic/main/20220409/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20220409234507.1phl2u16wtuo.png"><br>使用修剪来加速推理时，一个重要的问题是，所讨论的硬件是否可以实际利用修剪的表示形式。通常需要强加某种结构来管理可以修剪哪些连接，以便看到显着的改进。例如，这可能意味着删除权重矩阵的整行，而不是矩阵的任意元素。以需要遵循特定结构的方式修剪称为结构化修剪，而没有结构要求的修剪称为非结构化修剪。 使用结构化而不是非结构化修剪会带来权衡。粗略地说，结构越严格，可以删除的连接就越少，而不会严重损害网络的准确性。这是因为非结构化修剪可以更自由地删除那些对网络性能损害最小的权重。在实践中，决定是否使用结构化修剪以及如果是，要施加什么结构要求取决于特定应用程序的要求以及用于推理的硬件。</p>
<h1 id="GPU设计准则"><a href="#GPU设计准则" class="headerlink" title="GPU设计准则"></a>GPU设计准则</h1><p>参考了文章</p>
<h2 id="latency-hiding-with-TLP-and-ILP"><a href="#latency-hiding-with-TLP-and-ILP" class="headerlink" title="latency hiding with TLP and ILP"></a>latency hiding with TLP and ILP</h2><p>如果 GPU 上驻留了足够的warp（如果我们有足够的 TLP），则在warp之间切换可以完全隐藏长延时操作的成本。我们将程序中的 TLP 数量量化为占用率occupancy，即可用（发出的）warp与 GPU 可支持的最大warp数之比。更高的占用率产生更好的延迟隐藏能力，这使我们能够实现充分利用。<br>另一种延迟隐藏策略是利用指令级并行性（ILP）及其利用单个线程中多个内存操作的延迟重叠的能力。由于 GPU 的内存系统是深度流水线的，因此线程在变为非活动状态之前可能会发出多个独立的长延迟操作，并且这些多个操作将共同产生与单个操作大致相同的延迟。虽然这产生了显著的性能优势，但它依赖于程序员向硬件公开独立的内存操作。我们可以通过将多个独立任务分配给同一线程（“线程粗化”）来实现此目标。</p>
<p>GPU 具有固定数量的寄存器。TLP 需要许多驻留warp，每个warp都需要寄存器。ILP 会增加每个线程的工作，因此每个线程需要更多的寄存器。因此，TLP和ILP是对立的，要充分利用这两种技术，就需要仔细平衡这两种技术。虽然TLP通常用于所有GPU计算，但ILP是一个较少探索的领域。</p>
<h2 id="load-balancing"><a href="#load-balancing" class="headerlink" title="load-balancing"></a>load-balancing</h2><p>我们现在转向的问题是，确保所有计算单元在每个周期上都做有用的工作，并且从这些warp访问的内存被合并以确保峰值内存性能。在SpMV和SpMM的content中，这种“负载平衡”问题有两个方面：</p>
<ol>
<li>warp之间的负载不均。某些 CTA(block) 或 warp 分配的工作量可能比其他 CTA 或 warp 少，这可能导致这些负载较少的计算单元处于空闲状态，而负载较多的计算单元继续执行有用的工作。在本文中，我们称之为“Type 1”负载不平衡。 </li>
<li>warp内部的负载不均。在两个方面，我们统称为“Type 2”负载不平衡。<br>(a) 某些warp可能没有足够的work来占用warp中的所有32个线程。在这种情况下，线程单元处于空闲状态，我们会损失性能。<br>(b) 某些warp可能会将不同的任务分配给不同的线程。 在这种情况下，线程内的 SIMT 执行意味着某些线程处于空闲状态，而其他线程正在运行;此外，执行过程中的warp分化意味着整个warp中的内存访问不太可能合并。</li>
</ol>
]]></content>
      <categories>
        <category>矩阵计算</category>
      </categories>
      <tags>
        <tag>matrix</tag>
        <tag>gpu</tag>
      </tags>
  </entry>
  <entry>
    <title>warp function</title>
    <url>/project/2022/04/08/warp-function/</url>
    <content><![CDATA[<p>以下是关于warp function的一些理解<br>主要参考资料是nVidia的官方文档</p>
<h1 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h1><p>warp的概念不加赘述，且建议在<strong>capability 7.x以上且cuda9.0以上</strong>的GPU上测试，有些函数在例如 __any, __all, and __ballot等在cuda9.0上已经被移除。</p>
<blockquote>
<p>predicate表示线程的一种状况<br>以下所有的实例，使用一个block，block块的大小是32，所说的线程号就是laneID<br>mask中的第i个bit表示第i个线程</p>
</blockquote>
<h1 id="warp-vote-functions"><a href="#warp-vote-functions" class="headerlink" title="warp vote functions"></a>warp vote functions</h1><ul>
<li>允许给定warp中的线程执行规约和广播操作</li>
<li>所有线程的lane的mask必须一致</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> __all_sync(<span class="type">unsigned</span> mask, <span class="type">int</span> predicate);</span><br><span class="line"><span class="type">int</span> __any_sync(<span class="type">unsigned</span> mask, <span class="type">int</span> predicate);</span><br><span class="line"><span class="type">unsigned</span> __ballot_sync(<span class="type">unsigned</span> mask, <span class="type">int</span> predicate);</span><br><span class="line"><span class="type">unsigned</span> __activemask()</span><br></pre></td></tr></table></figure>
<p><code>__all_sync</code> 评估<code>mask</code>中所有non-exited的线程（线程对应mask的位是1）的predicate，返回非零值当且仅当mask中对应线程的predicate都是非零的。</p>
<p><code>__any_sync</code> 评估<code>mask</code>中所有non-exited的线程（线程对应mask的位是1）的predicate，返回非零值当且仅当mask中对应线程的predicate存在非零的。</p>
<p><code>_ballot_sync</code>评估<code>mask</code>中所有non-exited线程的predicate，返回一个unsigned数，其第N位为1当且仅当<code>mask</code>中线程的predicate非零</p>
<p><code>__activemask()</code> 返回unsigned数 <code>mask</code>，表示这个warp中所有的active状态的线程</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">wall</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> laneId=threadIdx.x &amp; <span class="number">0x1f</span>;</span><br><span class="line">    <span class="type">int</span> predicate= laneId%<span class="number">2</span>;</span><br><span class="line">    <span class="type">unsigned</span> n;</span><br><span class="line">    n=__all_sync(<span class="number">0x55555555</span>,predicate);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Thread %d final n= %x\n&quot;</span>, threadIdx.x, n);</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>0x55555555</code>表示所有偶数位是1，奇数位是0。<code>predicate</code>是所有的偶数线程是0，奇数线程是1。在<code>__all_sync</code>下，所有线程的n是0，因为其只统计mask中non-exited的线程，<code>0x55555555</code>使得<code>__all_sync</code>只检查偶数位的线程，结果偶数位线程的predicate都是0。其余函数同理。</p>
<h1 id="warp-match-functions"><a href="#warp-match-functions" class="headerlink" title="warp match functions"></a>warp match functions</h1><ul>
<li>执行warp内线程之间变量的广播和比较操作</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">unsigned</span> <span class="type">int</span> __match_any_sync(<span class="type">unsigned</span> mask, T value);</span><br><span class="line"><span class="type">unsigned</span> <span class="type">int</span> __match_all_sync(<span class="type">unsigned</span>  mask, T value, <span class="type">int</span> *pred)</span><br><span class="line"><span class="comment">//T可以是int/unsigned int/long/unsigned long/long long/unsigned long long/float/double</span></span><br></pre></td></tr></table></figure>






<h1 id="warp-shuffle-function"><a href="#warp-shuffle-function" class="headerlink" title="warp shuffle function"></a>warp shuffle function</h1><ul>
<li>交换warp内部的线程的值</li>
<li>采用可选的width，必须是2的幂次，且不能大于warpsize</li>
<li>mask的值没有影响，不管mask是什么，结果都一致<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">T __shfl_sync(<span class="type">unsigned</span> mask, T var, <span class="type">int</span> srcLane, <span class="type">int</span> width=warpSize);</span><br><span class="line">T __shfl_up_sync(<span class="type">unsigned</span> mask, T var, <span class="type">unsigned</span> <span class="type">int</span> delta, <span class="type">int</span> width=warpSize);</span><br><span class="line">T __shfl_down_sync(<span class="type">unsigned</span> mask, T var, <span class="type">unsigned</span> <span class="type">int</span> delta, <span class="type">int</span> width=warpSize);</span><br><span class="line">T __shfl_xor_sync(<span class="type">unsigned</span> mask, T var, <span class="type">int</span> laneMask, <span class="type">int</span> width=warpSize);</span><br><span class="line"></span><br><span class="line"><span class="comment">//T can be int, unsigned int, long, unsigned long, long long, unsigned long long, float or double. With the cuda_fp16.h header included, T can also be __halfor __half2. Similarly, with the cuda_bf16.h header included, T can also be __nv_bfloat16 or __nv_bfloat162.</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<code>__shfl_sync() </code>返回srclane号线程的var，<code>width</code>将warpsize的线程数进行划分，每个子段长度为<code>width</code>。每个<code>width</code>中的线程得到<code>srclane</code>所指示的<code>var</code>，注意这里<code>srclane</code>都是<code>width</code>中的相对位置。<br>若是每个线程的<code>var</code>是它本身的线程值，那么<blockquote>
<p><code>__shfl_sync(mask,threadIdx.x,0,4)</code>，得到的结果是 4x0, 4x4, 4x8, 4x12, 4x16, 4x20, 4x24, 4x28, 4x32<br><code>__shfl_sync(mask,x,2,8)</code>, 得到的结果是2x8, 10x8, 18x8, 26x8</p>
</blockquote>
</li>
</ul>
<p><code>_shfl_up_sync()</code> 返回向前偏移为 <code>delta</code> 的线程中的变量 <code>var</code> 的值，其余线程返回0。<code>width</code>将warpsize划分成warpsize&#x2F;width个部分，每个部分返回的是当前的线程-delta的线程的value，若是减法结果为-，那么结果就不会变。注意这里是相对值，记得上面这个减法必须是要一个分组内。</p>
<blockquote>
<p>例如<code>n=__shfl_up_sync(0xffffffff,value,15,16);</code><br>结果是0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 0 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 16</p>
</blockquote>
<p><code>__shfl_down_sync()</code> 线程返回向后偏移为 delta 的线程中的变量 var 的值，其余线程返回0 。</p>
<blockquote>
<p>调用 <code>__shfl_down_sync(mask, x, 2, 16)</code>; 则标号为 0-13 的线程分别获得标号为 2-15 的线程中变量 x 的值；标号为 16 -29 的线程分别获得标号为 18 - 31 的线程中变量 x 的值。</p>
</blockquote>
<p><code>__shfl_xor_sync()</code>通过对调用者的通道ID与<code>laneMask</code>进行按位异或（XOR）运算来计算源通道ID。返回值为计算所得源通道中的var值。此模式实现了蝶形寻址模式。如果<code>width</code>小于warpsize，那么对于异或的结果，若是处于前面的group，那么可以获取异或的结果，若是处于后面的group，则会返回本身的var</p>
<blockquote>
<p>例如<code>n=__shfl_xor_sync(0,threadIdx.x,3,4);</code>的结果是3 2 1 0 7 6 5 4 11 10 9 8 15 14 13 12 19 18 17 16 23 22 21 27 26 25 24 31 30 29 28<br>例如<code>n=__shfl_xor_sync(0,threadIdx.x,3,2);</code>的结果是0 1 1 0 4 5 5 4 8 9 9 8 12 13 13 12 16 17 17 16 20 21 21 20 24 25 25 24 28 29 29 28</p>
</blockquote>
]]></content>
      <categories>
        <category>cuda基础学习</category>
      </categories>
      <tags>
        <tag>gpu</tag>
        <tag>cuda</tag>
      </tags>
  </entry>
  <entry>
    <title>动态并行</title>
    <url>/project/2022/02/28/%E5%8A%A8%E6%80%81%E5%B9%B6%E8%A1%8C/</url>
    <content><![CDATA[<h1 id="动态并行"><a href="#动态并行" class="headerlink" title="动态并行"></a>动态并行</h1><p>CUDA的动态并行允许在GPU端直接创建和同步新的GPU内核。在GPU端直接创建工作的能力可以减少在主机和设备之间传输执行控制和数据的需求，因为在设备上执行的线程可以在<strong>运行时</strong>决定启动配置。</p>
<h2 id="嵌套执行"><a href="#嵌套执行" class="headerlink" title="嵌套执行"></a>嵌套执行</h2><p>在动态并行中，内核执行分为两种类型：父母和孩子。父线程、父线程块或父网格启动一个新的网格，即子网格。子线程、子线程块或子网格被父母启动。子网格必须在父线程、父线程块或父网格完成之前完成。只有在所有的子网格都完成之后，父母才会完成。</p>
<p>下图说明了父网格和子网格的使用范围。主机线程配置和启动父网格，父网格配置和启动子网格。在线程创建的所有子网格都完成之后，父网格才会完成。如果调用的线程没有显式同步启动子网格，那么运行时保证父母和孩子之间的隐式同步。下图在父线程中设置了栅栏，从而可以与其子网格显式同步。</p>
<div  align="center">    
 <img src="https://cdn.jsdelivr.net/gh/HURONG0510/blogpic@main/20220228/20220228120642.58dizq8tk7o0.webp" width = "400" height = "200" />
</div>

<blockquote>
<p>设置栅栏，需要补充</p>
</blockquote>
<ul>
<li>设备线程中的网格启动，在线程块间是可见的。在线程块中，只有所有线程创建的子网格完成之后，线程块才结束。如果线程块中的线程在所有网格完成之前退出，那么在那些子网格上隐式同步会被触发。</li>
<li>当父母启动一个子网格，父线程块与孩子显式同步之后，孩子才能开始执行。</li>
<li>父网格和子网格共享相同的全局和常量内存存储，但他们有不同的局部内存和共享内存。</li>
<li>父网格和子网格可以对全局内存并发存取。有两个时刻，子网格和他的父线程见到的内存完全相同：<ul>
<li>子网格开始时</li>
<li>子网格完成时</li>
</ul>
</li>
<li>共享内存和局部内存分别于线程块或线程来说是私有的，同时在父母和孩子之间不是可见或一致的。局部内存对线程来说是私有存储，并且对该线程外部不可见。当启动一个子网格时，向局部内存传递一个指针作为参数是无效的。</li>
</ul>
<p>下图表示在GPU上嵌套hello world，每个网格的第0号线程输出hello world。</p>
<table>
<thead>
<tr>
<th><img src="https://raw.githubusercontent.com/HURONG0510/blogpic/main/20220228/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20220228213943.1z5k28bd1se8.png"></th>
<th><img src="https://raw.githubusercontent.com/HURONG0510/blogpic/main/20220228/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20220228214303.20t4lvy2suw0.png"></th>
</tr>
</thead>
</table>
<p>因为动态并行是由设备运行时库所支持的，所以函数必须在命令行使用 <strong>-lcudadevrt</strong>  进行明确链接。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nvcc -<span class="built_in">arch</span>=sm_35 -rdc=<span class="literal">true</span> nestedHelloWorld.cu -o hestHelloWorld -lcudadevrt</span><br></pre></td></tr></table></figure>

<p>当**-rdc** 标志为true，他强制生成可重定位的设备代码，这是动态并行的一个要求。</p>
<h2 id="动态并行的限制条件"><a href="#动态并行的限制条件" class="headerlink" title="动态并行的限制条件"></a>动态并行的限制条件</h2><p>动态并行只有在计算能力为3.5或更高的设备上才能被支持。通过动态并行调用的内核不能在物理方面独立的设备上启动。动态并行的最大嵌套深度限制为24，但实际上，在每一个新的级别中大多数内核受限于设备运行时系统需要的内存数量。因为为了对每个嵌套层中的父网格和子网格之间进行同步管理，设备运行时需要保留额外的内存。</p>
]]></content>
      <categories>
        <category>cuda基础学习</category>
      </categories>
      <tags>
        <tag>gpu</tag>
        <tag>cuda</tag>
      </tags>
  </entry>
  <entry>
    <title>cuda的进阶学习</title>
    <url>/project/2022/03/06/cuda%E7%9A%84%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/441146275">[施工中] CUDA GEMM 理论性能分析与 kernel 优化</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/413145211">英伟达GPU架构演进近十年，从费米到安培</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/423992093">CUDA高性能计算经典问题（二）—— 前缀和（Prefix Sum）</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/138668785">处理器和GPU的计算能力如何计算？</a></p>
<p>FFMA理论算力&#x3D;cuda core * 核心频率 *2<br>(这里的2表示一个FMA一个时钟周期可以进行2次乘或加的运算)</p>
<p>实际算力&#x3D;访存比*带宽</p>
<p>关于<a href="https://zhuanlan.zhihu.com/p/441146275">cuda femm</a>中的<a href="https://github.com/Yinghan-Li/YHs_Sample/blob/master/cuda/gemm/sgemm.cu">代码</a>的一些笔记。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdint&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdlib&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cmath&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">random_init</span><span class="params">(<span class="type">float</span> *data, <span class="type">size_t</span> size)</span> &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; size; ++i) &#123;</span><br><span class="line">        data[i] = <span class="type">float</span>(rand()) / RAND_MAX;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">bool</span> <span class="title function_">check</span><span class="params">(<span class="type">const</span> <span class="type">float</span> *A,</span></span><br><span class="line"><span class="params">           <span class="type">const</span> <span class="type">float</span> *B,</span></span><br><span class="line"><span class="params">           <span class="type">const</span> <span class="type">float</span> *C,</span></span><br><span class="line"><span class="params">           <span class="type">int</span> m, <span class="type">int</span> n, <span class="type">int</span> k)</span> &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; m; ++i) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; n; ++j) &#123;</span><br><span class="line">            <span class="type">float</span> sum = <span class="number">0.f</span>;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> p = <span class="number">0</span>; p &lt; k; ++p) &#123;</span><br><span class="line">                sum += A[i * k + p] * B[j + p * n];</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">std</span>::<span class="built_in">fabs</span>(sum - C[i * n + j]) / <span class="built_in">std</span>::<span class="built_in">fabs</span>(sum) &gt; <span class="number">1e-5</span>f) &#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;C[%d][%d] not match, %f vs %f\n&quot;</span>, i, j, sum, C[i * n + j]);</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__device__ __forceinline__</span><br><span class="line"><span class="type">uint32_t</span> <span class="title function_">smem_u32addr</span><span class="params">(<span class="type">const</span> <span class="type">void</span> *smem_ptr)</span> &#123;</span><br><span class="line">    <span class="type">uint32_t</span> addr;</span><br><span class="line">    <span class="keyword">asm</span> (<span class="string">&quot;&#123;.reg .u64 u64addr;\n&quot;</span></span><br><span class="line">         <span class="string">&quot; cvta.to.shared.u64 u64addr, %1;\n&quot;</span></span><br><span class="line">         <span class="string">&quot; cvt.u32.u64 %0, u64addr;&#125;\n&quot;</span></span><br><span class="line">         : <span class="string">&quot;=r&quot;</span>(addr)</span><br><span class="line">         : <span class="string">&quot;l&quot;</span>(smem_ptr)</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> addr;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__device__ __forceinline__</span><br><span class="line"><span class="type">void</span> <span class="title function_">ldg32_nc</span><span class="params">(<span class="type">float</span> &amp;reg, <span class="type">const</span> <span class="type">void</span> *ptr, <span class="type">bool</span> guard)</span> &#123;</span><br><span class="line">    <span class="keyword">asm</span> <span class="title function_">volatile</span> <span class="params">(</span></span><br><span class="line"><span class="params">        <span class="string">&quot;&#123;.reg .pred p;\n&quot;</span></span></span><br><span class="line"><span class="params">        <span class="string">&quot; setp.ne.b32 p, %2, 0;\n&quot;</span></span></span><br><span class="line"><span class="params">#<span class="keyword">if</span> __CUDACC_VER_MAJOR__ &gt;= <span class="number">11</span> &amp;&amp; __CUDACC_VER_MINOR__ &gt;= <span class="number">4</span> &amp;&amp; \</span></span><br><span class="line"><span class="params">    __CUDA_ARCH__ &gt;= <span class="number">750</span></span></span><br><span class="line"><span class="params">        <span class="string">&quot; @p ld.global.nc.L2::128B.f32 %0, [%1];&#125;\n&quot;</span></span></span><br><span class="line"><span class="params">#<span class="keyword">else</span></span></span><br><span class="line"><span class="params">        <span class="string">&quot; @p ld.global.nc.f32 %0, [%1];&#125;\n&quot;</span></span></span><br><span class="line"><span class="params">#endif</span></span><br><span class="line"><span class="params">        : <span class="string">&quot;=f&quot;</span>(reg)</span></span><br><span class="line"><span class="params">        : <span class="string">&quot;l&quot;</span>(ptr), <span class="string">&quot;r&quot;</span>((<span class="type">int</span>)guard)</span></span><br><span class="line"><span class="params">    )</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__device__ __forceinline__</span><br><span class="line"><span class="type">void</span> <span class="title function_">ldg32_nc_0</span><span class="params">(<span class="type">float</span> &amp;reg, <span class="type">const</span> <span class="type">void</span> *ptr, <span class="type">bool</span> guard)</span> &#123;</span><br><span class="line">    <span class="keyword">asm</span> <span class="title function_">volatile</span> <span class="params">(</span></span><br><span class="line"><span class="params">        <span class="string">&quot;&#123;.reg .pred p;\n&quot;</span></span></span><br><span class="line"><span class="params">        <span class="string">&quot; setp.ne.b32 p, %2, 0;\n&quot;</span></span></span><br><span class="line"><span class="params">        <span class="string">&quot; @!p mov.b32 %0, 0;\n&quot;</span></span></span><br><span class="line"><span class="params">#<span class="keyword">if</span> __CUDACC_VER_MAJOR__ &gt;= <span class="number">11</span> &amp;&amp; __CUDACC_VER_MINOR__ &gt;= <span class="number">4</span> &amp;&amp; \</span></span><br><span class="line"><span class="params">    __CUDA_ARCH__ &gt;= <span class="number">750</span></span></span><br><span class="line"><span class="params">        <span class="string">&quot; @p ld.global.nc.L2::128B.f32 %0, [%1];&#125;\n&quot;</span></span></span><br><span class="line"><span class="params">#<span class="keyword">else</span></span></span><br><span class="line"><span class="params">        <span class="string">&quot; @p ld.global.nc.f32 %0, [%1];&#125;\n&quot;</span></span></span><br><span class="line"><span class="params">#endif</span></span><br><span class="line"><span class="params">        : <span class="string">&quot;=f&quot;</span>(reg)</span></span><br><span class="line"><span class="params">        : <span class="string">&quot;l&quot;</span>(ptr), <span class="string">&quot;r&quot;</span>((<span class="type">int</span>)guard)</span></span><br><span class="line"><span class="params">    )</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__device__ __forceinline__</span><br><span class="line"><span class="type">void</span> <span class="title function_">stg32</span><span class="params">(<span class="type">const</span> <span class="type">float</span> &amp;reg, <span class="type">void</span> *ptr, <span class="type">bool</span> guard)</span> &#123;</span><br><span class="line">    <span class="keyword">asm</span> <span class="title function_">volatile</span> <span class="params">(</span></span><br><span class="line"><span class="params">        <span class="string">&quot;&#123;.reg .pred p;\n&quot;</span></span></span><br><span class="line"><span class="params">        <span class="string">&quot; setp.ne.b32 p, %2, 0;\n&quot;</span></span></span><br><span class="line"><span class="params">        <span class="string">&quot; @p st.global.f32 [%0], %1;&#125;\n&quot;</span></span></span><br><span class="line"><span class="params">        : : <span class="string">&quot;l&quot;</span>(ptr), <span class="string">&quot;f&quot;</span>(reg), <span class="string">&quot;r&quot;</span>((<span class="type">int</span>)guard)</span></span><br><span class="line"><span class="params">    )</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__device__ __forceinline__</span><br><span class="line"><span class="type">void</span> <span class="title function_">lds128</span><span class="params">(<span class="type">float</span> &amp;reg0, <span class="type">float</span> &amp;reg1,</span></span><br><span class="line"><span class="params">            <span class="type">float</span> &amp;reg2, <span class="type">float</span> &amp;reg3,</span></span><br><span class="line"><span class="params">            <span class="type">const</span> <span class="type">uint32_t</span> &amp;addr)</span> &#123;</span><br><span class="line">    <span class="keyword">asm</span> <span class="title function_">volatile</span> <span class="params">(</span></span><br><span class="line"><span class="params">        <span class="string">&quot;ld.shared.v4.f32 &#123;%0, %1, %2, %3&#125;, [%4];\n&quot;</span></span></span><br><span class="line"><span class="params">        : <span class="string">&quot;=f&quot;</span>(reg0), <span class="string">&quot;=f&quot;</span>(reg1), <span class="string">&quot;=f&quot;</span>(reg2), <span class="string">&quot;=f&quot;</span>(reg3)</span></span><br><span class="line"><span class="params">        : <span class="string">&quot;r&quot;</span>(addr)</span></span><br><span class="line"><span class="params">    )</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__device__ __forceinline__</span><br><span class="line"><span class="type">void</span> <span class="title function_">sts32</span><span class="params">(<span class="type">const</span> <span class="type">float</span> &amp;reg, <span class="type">const</span> <span class="type">uint32_t</span> &amp;addr)</span> &#123;</span><br><span class="line">    <span class="keyword">asm</span> <span class="title function_">volatile</span> <span class="params">(</span></span><br><span class="line"><span class="params">        <span class="string">&quot;st.shared.f32 [%0], %1;\n&quot;</span></span></span><br><span class="line"><span class="params">        : : <span class="string">&quot;r&quot;</span>(addr), <span class="string">&quot;f&quot;</span>(reg)</span></span><br><span class="line"><span class="params">    )</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__device__ __forceinline__</span><br><span class="line"><span class="type">void</span> <span class="title function_">sts128</span><span class="params">(<span class="type">const</span> <span class="type">float</span> &amp;reg0, <span class="type">const</span> <span class="type">float</span> &amp;reg1,</span></span><br><span class="line"><span class="params">            <span class="type">const</span> <span class="type">float</span> &amp;reg2, <span class="type">const</span> <span class="type">float</span> &amp;reg3,</span></span><br><span class="line"><span class="params">            <span class="type">const</span> <span class="type">uint32_t</span> &amp;addr)</span> &#123;</span><br><span class="line">    <span class="keyword">asm</span> <span class="title function_">volatile</span> <span class="params">(</span></span><br><span class="line"><span class="params">        <span class="string">&quot;st.shared.v4.f32 [%0], &#123;%1, %2, %3, %4&#125;;\n&quot;</span></span></span><br><span class="line"><span class="params">        : : <span class="string">&quot;r&quot;</span>(addr), <span class="string">&quot;f&quot;</span>(reg0), <span class="string">&quot;f&quot;</span>(reg1), <span class="string">&quot;f&quot;</span>(reg2), <span class="string">&quot;f&quot;</span>(reg3)</span></span><br><span class="line"><span class="params">    )</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">StgFrag</span> &#123;</span></span><br><span class="line">    <span class="type">float</span> data[<span class="number">4</span>][<span class="number">4</span>];</span><br><span class="line"></span><br><span class="line">    __device__ __forceinline__</span><br><span class="line">    <span class="title function_">StgFrag</span><span class="params">(<span class="type">const</span> <span class="type">float</span> (&amp;C_frag)[<span class="number">8</span>][<span class="number">8</span>], <span class="type">int</span> tile_x, <span class="type">int</span> tile_y)</span> &#123;</span><br><span class="line">        <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; ++i) &#123;</span><br><span class="line">            <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; <span class="number">4</span>; ++j) &#123;</span><br><span class="line">                data[i][j] = C_frag[tile_y * <span class="number">4</span> + i][tile_x * <span class="number">4</span> + j];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">__device__ __noinline__</span><br><span class="line"><span class="type">void</span> <span class="title function_">C_tile_wb</span><span class="params">(StgFrag C_frag,</span></span><br><span class="line"><span class="params">               <span class="type">float</span> *C_stg_ptr,</span></span><br><span class="line"><span class="params">               <span class="type">const</span> <span class="type">float</span> *C_lds_ptr,</span></span><br><span class="line"><span class="params">               <span class="type">uint32_t</span> C_sts_addr,</span></span><br><span class="line"><span class="params">               <span class="type">uint32_t</span> m,</span></span><br><span class="line"><span class="params">               <span class="type">uint32_t</span> n,</span></span><br><span class="line"><span class="params">               <span class="type">uint32_t</span> m_idx,</span></span><br><span class="line"><span class="params">               <span class="type">uint32_t</span> n_idx)</span> &#123;</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; ++i) &#123;</span><br><span class="line">        sts128(C_frag.data[i][<span class="number">0</span>],</span><br><span class="line">               C_frag.data[i][<span class="number">1</span>],</span><br><span class="line">               C_frag.data[i][<span class="number">2</span>],</span><br><span class="line">               C_frag.data[i][<span class="number">3</span>],</span><br><span class="line">               C_sts_addr + i * <span class="number">8</span> * <span class="keyword">sizeof</span>(float4));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="type">uint32_t</span> m_guard = m &lt; m_idx ? <span class="number">0</span> : m - m_idx;</span><br><span class="line"></span><br><span class="line">    <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">16</span>; ++i) &#123;</span><br><span class="line">        stg32(C_lds_ptr[i * <span class="number">32</span>],</span><br><span class="line">              C_stg_ptr + i * n,</span><br><span class="line">              i &lt; m_guard &amp;&amp; n_idx &lt; n);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * matrix A, B and C: row-major</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * mma block:</span></span><br><span class="line"><span class="comment"> * thread block tile: m128n128k8</span></span><br><span class="line"><span class="comment"> * warp tile: m32n64k8</span></span><br><span class="line"><span class="comment"> * thread tile: m8n8k8</span></span><br><span class="line"><span class="comment"> * thread fragment:</span></span><br><span class="line"><span class="comment"> *     matrixA: 8x1 FP32</span></span><br><span class="line"><span class="comment"> *     matrixB: 1x8 FP32</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * ----------------------------------------------------------------</span></span><br><span class="line"><span class="comment"> * thread block tile map:</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *                                128</span></span><br><span class="line"><span class="comment"> *                    --|---------------------|</span></span><br><span class="line"><span class="comment"> *             B_tile  8|                     |</span></span><br><span class="line"><span class="comment"> *                    --|---------------------|</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *  A_tile   | 8 |      |    64    |</span></span><br><span class="line"><span class="comment"> *         --|---|    --|----------|----------|</span></span><br><span class="line"><span class="comment"> *           |   |    32|  warp_0  |  warp_1  |</span></span><br><span class="line"><span class="comment"> *           |   |    --|----------|----------|</span></span><br><span class="line"><span class="comment"> *           |   |      |  warp_2  |  warp_3  |</span></span><br><span class="line"><span class="comment"> *        128|   |      |----------|----------|</span></span><br><span class="line"><span class="comment"> *           |   |      |  warp_4  |  warp_5  |</span></span><br><span class="line"><span class="comment"> *           |   |      |----------|----------|</span></span><br><span class="line"><span class="comment"> *           |   |      |  warp_6  |  warp_7  |</span></span><br><span class="line"><span class="comment"> *         --|---|      |----------|----------|</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * ----------------------------------------------------------------</span></span><br><span class="line"><span class="comment"> * warp tile map:</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &#x27;z&#x27; thread map to avoid LDS.128 shared memory broadcast limitation.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *              |              32               ||</span></span><br><span class="line"><span class="comment"> *     B_frag --|---|---|---|---|---|---|---|---||---|---|---|---|---|---|---|---|</span></span><br><span class="line"><span class="comment"> *             1|///|   |   |   |   |   |   |   ||///|   |   |   |   |   |   |   |</span></span><br><span class="line"><span class="comment"> *            --|---|---|---|---|---|---|---|---||---|---|---|---|---|---|---|---|</span></span><br><span class="line"><span class="comment"> * A_frag       | 4 |                           ||</span></span><br><span class="line"><span class="comment"> *    | 1 |                                     ||</span></span><br><span class="line"><span class="comment"> *  --|---|--   |---|---|---|---|---|---|---|---||---|---------------------------|</span></span><br><span class="line"><span class="comment"> *    |///|4    |t0 |t2 |t4 |t6 |t8 |t10|t12|t14||t0 |                           |</span></span><br><span class="line"><span class="comment"> *    |---|--   |---|---|---|---|---|---|---|---||---|                           |</span></span><br><span class="line"><span class="comment"> *    |   |     |t1 |t3 |t5 |t7 |t9 |t11|t13|t15||                               |</span></span><br><span class="line"><span class="comment"> *  16|---|     |---|---|---|---|---|---|---|---||                               |</span></span><br><span class="line"><span class="comment"> *    |   |     |t16|t18|t20|t22|t24|t26|t28|t30||                               |</span></span><br><span class="line"><span class="comment"> *    |---|     |---|---|---|---|---|---|---|---||                               |</span></span><br><span class="line"><span class="comment"> *    |   |     |t17|t19|t21|t23|t25|t27|t29|t31||                               |</span></span><br><span class="line"><span class="comment"> *  ==|===|=====|===|===|===|===|===|===|===|===||===|============================</span></span><br><span class="line"><span class="comment"> *    |///|     |t0 |                           ||t0 |                           |</span></span><br><span class="line"><span class="comment"> *    |---|     |---|                           ||---|                           |</span></span><br><span class="line"><span class="comment"> *    |   |     |                               ||                               |</span></span><br><span class="line"><span class="comment"> *    |---|     |                               ||                               |</span></span><br><span class="line"><span class="comment"> *    |   |     |                               ||                               |</span></span><br><span class="line"><span class="comment"> *    |---|     |                               ||                               |</span></span><br><span class="line"><span class="comment"> *    |   |     |                               ||                               |</span></span><br><span class="line"><span class="comment"> *    |---|     |-------------------------------||-------------------------------|</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">__global__ __launch_bounds__(<span class="number">256</span>, <span class="number">2</span>)<span class="comment">//__launch_bounds__(maxThreadsPerBlock, minBlocksPerMultiprocessor)</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">sgemm_128x128x8_kernel</span><span class="params">(<span class="type">const</span> <span class="type">float</span> *A,</span></span><br><span class="line"><span class="params">                            <span class="type">const</span> <span class="type">float</span> *B,</span></span><br><span class="line"><span class="params">                            <span class="type">float</span> *C,</span></span><br><span class="line"><span class="params">                            <span class="type">uint32_t</span> m,</span></span><br><span class="line"><span class="params">                            <span class="type">uint32_t</span> n,</span></span><br><span class="line"><span class="params">                            <span class="type">uint32_t</span> k,</span></span><br><span class="line"><span class="params">                            <span class="type">uint32_t</span> A_ldg_step,    <span class="comment">// k * sizeof(float)</span></span></span><br><span class="line"><span class="params">                            <span class="type">uint32_t</span> B_ldg_step)</span> &#123;  <span class="comment">// n * sizeof(float) * 8</span></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * matrix A &amp; B thread block tile shared memory (double buffer)</span></span><br><span class="line"><span class="comment">     * matrix A: 132 * 8 * 4Byte/item * double buffer = 4.125KB * 2</span></span><br><span class="line"><span class="comment">     * matrix B: 128 * 8 * 4Byte/item * double buffer = 8KB</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * for double buffer faster switch, A_smem requires 8KB * 2 shared memory</span></span><br><span class="line"><span class="comment">     * and 16KB aligned, B_smem should be 8KB aligned, then the double buffer</span></span><br><span class="line"><span class="comment">     * can be switched by only 1 xor instruction:</span></span><br><span class="line"><span class="comment">     *     (uint32_t &amp;)A_smem ^= 0x2000;</span></span><br><span class="line"><span class="comment">     *     (uint32_t &amp;)B_smem ^= 0x1000;</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    __shared__ __align__(<span class="number">16</span> * <span class="number">1024</span>) <span class="type">char</span> smem[<span class="number">24</span> * <span class="number">1024</span>];</span><br><span class="line">    <span class="type">float</span> *A_smem = reinterpret_cast&lt;<span class="type">float</span> *&gt;(smem);</span><br><span class="line">    <span class="type">float</span> *B_smem = reinterpret_cast&lt;<span class="type">float</span> *&gt;(smem + <span class="number">16</span> * <span class="number">1024</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// A, B and C register fragment</span></span><br><span class="line">    <span class="type">float</span> A_frag[<span class="number">2</span>][<span class="number">8</span>];</span><br><span class="line">    <span class="type">float</span> B_frag[<span class="number">2</span>][<span class="number">8</span>];</span><br><span class="line">    <span class="type">float</span> C_frag[<span class="number">8</span>][<span class="number">8</span>];</span><br><span class="line">    <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">8</span>; ++i) &#123;</span><br><span class="line">        <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; <span class="number">8</span>; ++j) &#123;</span><br><span class="line">            C_frag[i][j] = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">uint32_t</span> lane_id = threadIdx.x % <span class="number">32</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">uint32_t</span> warp_id = threadIdx.x / <span class="number">32</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4x8 threads each warp for FFMA</span></span><br><span class="line">    <span class="type">const</span> <span class="type">uint32_t</span> mma_tid_x = (lane_id / <span class="number">2</span>) % <span class="number">8</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">uint32_t</span> mma_tid_y = (lane_id / <span class="number">16</span>) * <span class="number">2</span> + (lane_id % <span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// A_tile &amp; B_tile ldg pointer</span></span><br><span class="line">    <span class="type">const</span> <span class="type">char</span> *A_ldg_ptr = (<span class="type">const</span> <span class="type">char</span> *)(</span><br><span class="line">        A + (blockIdx.y * <span class="number">128</span> + threadIdx.x / <span class="number">8</span> * <span class="number">4</span>) * k + threadIdx.x % <span class="number">8</span>);</span><br><span class="line">    <span class="type">const</span> <span class="type">char</span> *B_ldg_ptr = (<span class="type">const</span> <span class="type">char</span> *)(</span><br><span class="line">        B + (threadIdx.x / <span class="number">32</span>) * n + blockIdx.x * <span class="number">128</span> + threadIdx.x % <span class="number">32</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// A_tile &amp; B_tile sts/lds pointer</span></span><br><span class="line">    <span class="comment">// using uint32_t pointer for faster double buffer switch</span></span><br><span class="line">    <span class="type">uint32_t</span> A_sts_addr = smem_u32addr(</span><br><span class="line">        A_smem + (threadIdx.x % <span class="number">8</span>) * <span class="number">132</span> + (threadIdx.x / <span class="number">8</span>) * <span class="number">4</span>);</span><br><span class="line">    <span class="type">uint32_t</span> B_sts_addr = smem_u32addr(</span><br><span class="line">        B_smem + (threadIdx.x / <span class="number">32</span>) * <span class="number">128</span> + (threadIdx.x % <span class="number">32</span>));</span><br><span class="line"></span><br><span class="line">    <span class="type">uint32_t</span> A_lds_addr = smem_u32addr(</span><br><span class="line">        A_smem + (warp_id / <span class="number">2</span>) * <span class="number">32</span> + mma_tid_y * <span class="number">4</span>);</span><br><span class="line">    <span class="type">uint32_t</span> B_lds_addr = smem_u32addr(</span><br><span class="line">        B_smem + (warp_id % <span class="number">2</span>) * <span class="number">64</span> + mma_tid_x * <span class="number">4</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ldg_guard to avoid LDG out of bound</span></span><br><span class="line">    <span class="type">uint32_t</span> A_ldg_guard = <span class="number">0</span>;</span><br><span class="line">    <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; ++i) &#123;</span><br><span class="line">        <span class="type">int</span> m_idx = blockIdx.y * <span class="number">128</span> + threadIdx.x / <span class="number">8</span> * <span class="number">4</span> + i;</span><br><span class="line">        <span class="keyword">if</span> (m_idx &lt; m) &#123;</span><br><span class="line">            A_ldg_guard |= (<span class="number">1u</span> &lt;&lt; i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">uint32_t</span> B_ldg_guard = <span class="number">0</span>;</span><br><span class="line">    <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; ++i) &#123;</span><br><span class="line">        <span class="type">int</span> n_idx = blockIdx.x * <span class="number">128</span> + threadIdx.x % <span class="number">32</span> + i * <span class="number">32</span>;</span><br><span class="line">        <span class="keyword">if</span> (n_idx &lt; n) &#123;</span><br><span class="line">            B_ldg_guard |= (<span class="number">1u</span> &lt;&lt; i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> A_ldg_reg[<span class="number">4</span>];</span><br><span class="line">    <span class="type">float</span> B_ldg_reg[<span class="number">4</span>];</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1&#x27;st A&amp;B tile loaded before the k_tile loop</span></span><br><span class="line">    <span class="type">uint32_t</span> k_tiles = (k + <span class="number">7</span>) / <span class="number">8</span> - <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// load 1&#x27;st tile to shared memory</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">uint32_t</span> first_k_tile = k - k_tiles * <span class="number">8</span>;</span><br><span class="line"></span><br><span class="line">        <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; ++i) &#123;</span><br><span class="line">            <span class="type">bool</span> guard = (A_ldg_guard &amp; (<span class="number">1u</span> &lt;&lt; i)) != <span class="number">0</span> &amp;&amp;</span><br><span class="line">                         threadIdx.x % <span class="number">8</span> &lt; first_k_tile;</span><br><span class="line">            ldg32_nc_0(A_ldg_reg[i],</span><br><span class="line">                       A_ldg_ptr + i * A_ldg_step,</span><br><span class="line">                       guard);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        sts128(A_ldg_reg[<span class="number">0</span>], A_ldg_reg[<span class="number">1</span>], A_ldg_reg[<span class="number">2</span>], A_ldg_reg[<span class="number">3</span>],</span><br><span class="line">               A_sts_addr);</span><br><span class="line"></span><br><span class="line">        <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; ++i) &#123;</span><br><span class="line">            <span class="type">bool</span> guard = (B_ldg_guard &amp; (<span class="number">1u</span> &lt;&lt; i)) != <span class="number">0</span> &amp;&amp;</span><br><span class="line">                         threadIdx.x / <span class="number">32</span> &lt; first_k_tile;</span><br><span class="line">            ldg32_nc_0(B_ldg_reg[i],</span><br><span class="line">                       B_ldg_ptr + i * <span class="number">32</span> * <span class="keyword">sizeof</span>(<span class="type">float</span>),</span><br><span class="line">                       guard);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; ++i) &#123;</span><br><span class="line">            sts32(B_ldg_reg[i], B_sts_addr + i * <span class="number">32</span> * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        __syncthreads();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// switch double buffer</span></span><br><span class="line">        A_sts_addr ^= <span class="number">0x2000</span>;</span><br><span class="line">        B_sts_addr ^= <span class="number">0x1000</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// ldg pointer for next tile</span></span><br><span class="line">        A_ldg_ptr += first_k_tile * <span class="keyword">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">        B_ldg_ptr += n * first_k_tile * <span class="keyword">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// load 1&#x27;st fragment</span></span><br><span class="line">    lds128(A_frag[<span class="number">0</span>][<span class="number">0</span>], A_frag[<span class="number">0</span>][<span class="number">1</span>], A_frag[<span class="number">0</span>][<span class="number">2</span>], A_frag[<span class="number">0</span>][<span class="number">3</span>],</span><br><span class="line">           A_lds_addr);</span><br><span class="line">    lds128(A_frag[<span class="number">0</span>][<span class="number">4</span>], A_frag[<span class="number">0</span>][<span class="number">5</span>], A_frag[<span class="number">0</span>][<span class="number">6</span>], A_frag[<span class="number">0</span>][<span class="number">7</span>],</span><br><span class="line">           A_lds_addr + <span class="number">16</span> * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    lds128(B_frag[<span class="number">0</span>][<span class="number">0</span>], B_frag[<span class="number">0</span>][<span class="number">1</span>], B_frag[<span class="number">0</span>][<span class="number">2</span>], B_frag[<span class="number">0</span>][<span class="number">3</span>],</span><br><span class="line">           B_lds_addr);</span><br><span class="line">    lds128(B_frag[<span class="number">0</span>][<span class="number">4</span>], B_frag[<span class="number">0</span>][<span class="number">5</span>], B_frag[<span class="number">0</span>][<span class="number">6</span>], B_frag[<span class="number">0</span>][<span class="number">7</span>],</span><br><span class="line">           B_lds_addr + <span class="number">32</span> * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// k_tiles loop</span></span><br><span class="line">    <span class="keyword">for</span> (; k_tiles &gt; <span class="number">0</span>; --k_tiles) &#123;</span><br><span class="line">        <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> k_frag = <span class="number">0</span>; k_frag &lt; <span class="number">8</span>; ++k_frag) &#123;</span><br><span class="line">            <span class="comment">// store next A&amp;B tile to shared memory</span></span><br><span class="line">            <span class="keyword">if</span> (k_frag == <span class="number">7</span>) &#123;</span><br><span class="line">                sts128(A_ldg_reg[<span class="number">0</span>], A_ldg_reg[<span class="number">1</span>], A_ldg_reg[<span class="number">2</span>], A_ldg_reg[<span class="number">3</span>],</span><br><span class="line">                       A_sts_addr);</span><br><span class="line">                <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; ++i) &#123;</span><br><span class="line">                    sts32(B_ldg_reg[i], B_sts_addr + i * <span class="number">32</span> * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                __syncthreads();</span><br><span class="line"></span><br><span class="line">                <span class="comment">// switch double buffer</span></span><br><span class="line">                A_lds_addr ^= <span class="number">0x2000</span>;</span><br><span class="line">                B_lds_addr ^= <span class="number">0x1000</span>;</span><br><span class="line">                A_sts_addr ^= <span class="number">0x2000</span>;</span><br><span class="line">                B_sts_addr ^= <span class="number">0x1000</span>;</span><br><span class="line"></span><br><span class="line">                <span class="comment">// ldg pointer for next tile</span></span><br><span class="line">                A_ldg_ptr += <span class="number">8</span> * <span class="keyword">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">                B_ldg_ptr += B_ldg_step;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// load next A&amp;B fragment from shared memory to register</span></span><br><span class="line">            lds128(A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">0</span>],</span><br><span class="line">                   A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">1</span>],</span><br><span class="line">                   A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">2</span>],</span><br><span class="line">                   A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">3</span>],</span><br><span class="line">                   A_lds_addr + (k_frag + <span class="number">1</span>) % <span class="number">8</span> * <span class="number">132</span> * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            lds128(A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">4</span>],</span><br><span class="line">                   A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">5</span>],</span><br><span class="line">                   A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">6</span>],</span><br><span class="line">                   A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">7</span>],</span><br><span class="line">                   A_lds_addr + ((k_frag + <span class="number">1</span>) % <span class="number">8</span> * <span class="number">132</span> + <span class="number">16</span>) * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            lds128(B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">0</span>],</span><br><span class="line">                   B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">1</span>],</span><br><span class="line">                   B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">2</span>],</span><br><span class="line">                   B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">3</span>],</span><br><span class="line">                   B_lds_addr + (k_frag + <span class="number">1</span>) % <span class="number">8</span> * <span class="number">128</span> * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            lds128(B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">4</span>],</span><br><span class="line">                   B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">5</span>],</span><br><span class="line">                   B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">6</span>],</span><br><span class="line">                   B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">7</span>],</span><br><span class="line">                   B_lds_addr + ((k_frag + <span class="number">1</span>) % <span class="number">8</span> * <span class="number">128</span> + <span class="number">32</span>) * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// load next A&amp;B tile</span></span><br><span class="line">            <span class="keyword">if</span> (k_frag == <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; ++i) &#123;</span><br><span class="line">                    ldg32_nc(A_ldg_reg[i],</span><br><span class="line">                             A_ldg_ptr + i * A_ldg_step,</span><br><span class="line">                             (A_ldg_guard &amp; (<span class="number">1u</span> &lt;&lt; i)) != <span class="number">0</span>);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; ++i) &#123;</span><br><span class="line">                    ldg32_nc(B_ldg_reg[i],</span><br><span class="line">                             B_ldg_ptr + i * <span class="number">32</span> * <span class="keyword">sizeof</span>(<span class="type">float</span>),</span><br><span class="line">                             (B_ldg_guard &amp; (<span class="number">1u</span> &lt;&lt; i)) != <span class="number">0</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// FFMA loop</span></span><br><span class="line">            <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">8</span>; ++i) &#123;</span><br><span class="line">                <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; <span class="number">8</span>; ++j) &#123;</span><br><span class="line">                    C_frag[i][j] += A_frag[k_frag % <span class="number">2</span>][i] *</span><br><span class="line">                                    B_frag[k_frag % <span class="number">2</span>][j];</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// FFMA for the last tile</span></span><br><span class="line">    <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> k_frag = <span class="number">0</span>; k_frag &lt; <span class="number">8</span>; ++k_frag) &#123;</span><br><span class="line">        <span class="keyword">if</span> (k_frag &lt; <span class="number">7</span>) &#123;</span><br><span class="line">            <span class="comment">// load next A&amp;B fragment from shared memory to register</span></span><br><span class="line">            lds128(A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">0</span>],</span><br><span class="line">                   A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">1</span>],</span><br><span class="line">                   A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">2</span>],</span><br><span class="line">                   A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">3</span>],</span><br><span class="line">                   A_lds_addr + (k_frag + <span class="number">1</span>) % <span class="number">8</span> * <span class="number">132</span> * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            lds128(A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">4</span>],</span><br><span class="line">                   A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">5</span>],</span><br><span class="line">                   A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">6</span>],</span><br><span class="line">                   A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">7</span>],</span><br><span class="line">                   A_lds_addr + ((k_frag + <span class="number">1</span>) % <span class="number">8</span> * <span class="number">132</span> + <span class="number">16</span>) * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            lds128(B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">0</span>],</span><br><span class="line">                   B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">1</span>],</span><br><span class="line">                   B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">2</span>],</span><br><span class="line">                   B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">3</span>],</span><br><span class="line">                   B_lds_addr + (k_frag + <span class="number">1</span>) % <span class="number">8</span> * <span class="number">128</span> * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            lds128(B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">4</span>],</span><br><span class="line">                   B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">5</span>],</span><br><span class="line">                   B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">6</span>],</span><br><span class="line">                   B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">7</span>],</span><br><span class="line">                   B_lds_addr + ((k_frag + <span class="number">1</span>) % <span class="number">8</span> * <span class="number">128</span> + <span class="number">32</span>) * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// FFMA loop</span></span><br><span class="line">        <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">8</span>; ++i) &#123;</span><br><span class="line">            <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; <span class="number">8</span>; ++j) &#123;</span><br><span class="line">                C_frag[i][j] += A_frag[k_frag % <span class="number">2</span>][i] *</span><br><span class="line">                                B_frag[k_frag % <span class="number">2</span>][j];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// C_tile write back, reuse A&amp;B tile shared memory buffer</span></span><br><span class="line">    <span class="type">uint32_t</span> C_sts_addr = smem_u32addr((float4 *)(smem + warp_id * <span class="number">2048</span>) +</span><br><span class="line">                                       mma_tid_y * <span class="number">4</span> * <span class="number">8</span> + mma_tid_x);</span><br><span class="line">    <span class="type">const</span> <span class="type">float</span> *C_lds_ptr = (<span class="type">float</span> *)(smem + warp_id * <span class="number">2048</span>) + lane_id;</span><br><span class="line"></span><br><span class="line">    <span class="type">uint32_t</span> m_idx = blockIdx.y * <span class="number">128</span> + warp_id / <span class="number">2</span> * <span class="number">32</span>;</span><br><span class="line">    <span class="type">uint32_t</span> n_idx = blockIdx.x * <span class="number">128</span> + warp_id % <span class="number">2</span> * <span class="number">64</span> + lane_id;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> *C_stg_ptr = C + m_idx * n + n_idx;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (m_idx &gt;= m) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (m_idx + <span class="number">32</span> &lt;= m) &#123;</span><br><span class="line">        <span class="type">uint32_t</span> n_guard = n &lt; n_idx ? <span class="number">0</span> : n - n_idx;</span><br><span class="line"></span><br><span class="line">        <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; ++i) &#123;</span><br><span class="line">            <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; <span class="number">2</span>; ++j) &#123;</span><br><span class="line">                __syncthreads();</span><br><span class="line"></span><br><span class="line">                <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> p = <span class="number">0</span>; p &lt; <span class="number">4</span>; ++p) &#123;</span><br><span class="line">                    sts128(C_frag[i * <span class="number">4</span> + p][j * <span class="number">4</span>],</span><br><span class="line">                           C_frag[i * <span class="number">4</span> + p][j * <span class="number">4</span> + <span class="number">1</span>],</span><br><span class="line">                           C_frag[i * <span class="number">4</span> + p][j * <span class="number">4</span> + <span class="number">2</span>],</span><br><span class="line">                           C_frag[i * <span class="number">4</span> + p][j * <span class="number">4</span> + <span class="number">3</span>],</span><br><span class="line">                           C_sts_addr + p * <span class="number">8</span> * <span class="keyword">sizeof</span>(float4));</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                __syncthreads();</span><br><span class="line"></span><br><span class="line">                <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> p = <span class="number">0</span>; p &lt; <span class="number">16</span>; ++p) &#123;</span><br><span class="line">                    stg32(C_lds_ptr[p * <span class="number">32</span>],</span><br><span class="line">                          C_stg_ptr + (i * <span class="number">16</span> + p) * n + j * <span class="number">32</span>,</span><br><span class="line">                          j * <span class="number">32</span> &lt; n_guard);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; ++i) &#123;</span><br><span class="line">            <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; <span class="number">2</span>; ++j) &#123;</span><br><span class="line">                StgFrag stg_frag(C_frag, j, i);</span><br><span class="line"></span><br><span class="line">                C_tile_wb(stg_frag,</span><br><span class="line">                          C_stg_ptr + i * <span class="number">16</span> * n + j * <span class="number">32</span>,</span><br><span class="line">                          C_lds_ptr,</span><br><span class="line">                          C_sts_addr,</span><br><span class="line">                          m,</span><br><span class="line">                          n,</span><br><span class="line">                          m_idx + i * <span class="number">16</span>,</span><br><span class="line">                          n_idx + j * <span class="number">32</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">int</span> m = <span class="number">5120</span>;</span><br><span class="line">    <span class="type">int</span> n = <span class="number">4096</span>;</span><br><span class="line">    <span class="type">int</span> k = <span class="number">4096</span>;</span><br><span class="line">    <span class="type">int</span> n_iter = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> *h_A, *h_B, *h_C;</span><br><span class="line">    cudaMallocHost(&amp;h_A, m * k * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    cudaMallocHost(&amp;h_B, k * n * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    cudaMallocHost(&amp;h_C, m * n * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    random_init(h_A, m * k);</span><br><span class="line">    random_init(h_B, k * n);</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> *d_A, *d_B, *d_C;</span><br><span class="line">    cudaMalloc(&amp;d_A, m * k * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    cudaMalloc(&amp;d_B, k * n * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    cudaMalloc(&amp;d_C, m * n * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line"></span><br><span class="line">    cudaMemcpy(d_A, h_A, m * k * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyDefault);</span><br><span class="line">    cudaMemcpy(d_B, h_B, k * n * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyDefault);</span><br><span class="line"></span><br><span class="line">    cudaEvent_t start, end;</span><br><span class="line">    cudaEventCreate(&amp;start);</span><br><span class="line">    cudaEventCreate(&amp;end);</span><br><span class="line"></span><br><span class="line">    dim3 <span class="title function_">grid</span><span class="params">((n + <span class="number">127</span>) / <span class="number">128</span>, (m + <span class="number">127</span>) / <span class="number">128</span>)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// warmup</span></span><br><span class="line">    sgemm_128x128x8_kernel&lt;&lt;&lt;grid, <span class="number">256</span>&gt;&gt;&gt;(</span><br><span class="line">        d_A, d_B, d_C, m, n, k, k * <span class="keyword">sizeof</span>(<span class="type">float</span>), n * <span class="keyword">sizeof</span>(<span class="type">float</span>) * <span class="number">8</span>);</span><br><span class="line"></span><br><span class="line">    cudaEventRecord(start);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n_iter; ++i) &#123;</span><br><span class="line">        sgemm_128x128x8_kernel&lt;&lt;&lt;grid, <span class="number">256</span>&gt;&gt;&gt;(</span><br><span class="line">            d_A, d_B, d_C, m, n, k, k * <span class="keyword">sizeof</span>(<span class="type">float</span>), n * <span class="keyword">sizeof</span>(<span class="type">float</span>) * <span class="number">8</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    cudaEventRecord(end);</span><br><span class="line">    cudaEventSynchronize(end);</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> ms;</span><br><span class="line">    cudaEventElapsedTime(&amp;ms, start, end);</span><br><span class="line">    cudaEventDestroy(start);</span><br><span class="line">    cudaEventDestroy(end);</span><br><span class="line"></span><br><span class="line">    <span class="type">long</span> workload = n_iter * <span class="type">long</span>(m) * n * k * <span class="number">2</span>;</span><br><span class="line">    <span class="type">double</span> gflops = (<span class="type">double</span>(workload) / <span class="number">1e9</span>) / (<span class="type">double</span>(ms) / <span class="number">1e3</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Performance: %fGFLOPS\n&quot;</span>, gflops);</span><br><span class="line"></span><br><span class="line">    cudaMemcpy(h_C, d_C, m * n * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyDefault);</span><br><span class="line"></span><br><span class="line">    <span class="type">bool</span> chk = check(h_A, h_B, h_C, m, n, k);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Matrix_C check: %s\n&quot;</span>, chk ? <span class="string">&quot;OK&quot;</span> : <span class="string">&quot;Failed&quot;</span>);</span><br><span class="line"></span><br><span class="line">    cudaFree(d_A);</span><br><span class="line">    cudaFree(d_B);</span><br><span class="line">    cudaFree(d_C);</span><br><span class="line">    cudaFreeHost(h_A);</span><br><span class="line">    cudaFreeHost(h_B);</span><br><span class="line">    cudaFreeHost(h_C);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>cuda基础学习</category>
      </categories>
      <tags>
        <tag>gpu</tag>
        <tag>cuda</tag>
      </tags>
  </entry>
</search>
