<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>动态并行</title>
    <url>/2022/02/28/%E5%8A%A8%E6%80%81%E5%B9%B6%E8%A1%8C/</url>
    <content><![CDATA[<h1 id="动态并行"><a href="#动态并行" class="headerlink" title="动态并行"></a>动态并行</h1><p>CUDA的动态并行允许在GPU端直接创建和同步新的GPU内核。在GPU端直接创建工作的能力可以减少在主机和设备之间传输执行控制和数据的需求，因为在设备上执行的线程可以在<strong>运行时</strong>决定启动配置。</p>
<h2 id="嵌套执行"><a href="#嵌套执行" class="headerlink" title="嵌套执行"></a>嵌套执行</h2><p>在动态并行中，内核执行分为两种类型：父母和孩子。父线程、父线程块或父网格启动一个新的网格，即子网格。子线程、子线程块或子网格被父母启动。子网格必须在父线程、父线程块或父网格完成之前完成。只有在所有的子网格都完成之后，父母才会完成。</p>
<p>下图说明了父网格和子网格的使用范围。主机线程配置和启动父网格，父网格配置和启动子网格。在线程创建的所有子网格都完成之后，父网格才会完成。如果调用的线程没有显式同步启动子网格，那么运行时保证父母和孩子之间的隐式同步。下图在父线程中设置了栅栏，从而可以与其子网格显式同步。</p>
<div  align="center">    
 <img src="https://cdn.jsdelivr.net/gh/HURONG0510/blogpic@main/20220228/20220228120642.58dizq8tk7o0.webp" width = "400" height = "200" />
</div>

<blockquote>
<p>设置栅栏，需要补充</p>
</blockquote>
<ul>
<li>设备线程中的网格启动，在线程块间是可见的。在线程块中，只有所有线程创建的子网格完成之后，线程块才结束。如果线程块中的线程在所有网格完成之前退出，那么在那些子网格上隐式同步会被触发。</li>
<li>当父母启动一个子网格，父线程块与孩子显式同步之后，孩子才能开始执行。</li>
<li>父网格和子网格共享相同的全局和常量内存存储，但他们有不同的局部内存和共享内存。</li>
<li>父网格和子网格可以对全局内存并发存取。有两个时刻，子网格和他的父线程见到的内存完全相同：<ul>
<li>子网格开始时</li>
<li>子网格完成时</li>
</ul>
</li>
<li>共享内存和局部内存分别于线程块或线程来说是私有的，同时在父母和孩子之间不是可见或一致的。局部内存对线程来说是私有存储，并且对该线程外部不可见。当启动一个子网格时，向局部内存传递一个指针作为参数是无效的。</li>
</ul>
<p>下图表示在GPU上嵌套hello world，每个网格的第0号线程输出hello world。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th><img src="https://raw.githubusercontent.com/HURONG0510/blogpic/main/20220228/微信截图_20220228213943.1z5k28bd1se8.png" alt=""></th>
<th><img src="https://raw.githubusercontent.com/HURONG0510/blogpic/main/20220228/微信截图_20220228214303.20t4lvy2suw0.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
</div>
<p>因为动态并行是由设备运行时库所支持的，所以函数必须在命令行使用 <strong>-lcudadevrt</strong>  进行明确链接。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nvcc -<span class="built_in">arch</span>=sm_35 -rdc=<span class="literal">true</span> nestedHelloWorld.cu -o hestHelloWorld -lcudadevrt</span><br></pre></td></tr></table></figure></p>
<p>当<strong>-rdc</strong> 标志为true，他强制生成可重定位的设备代码，这是动态并行的一个要求。</p>
<h2 id="动态并行的限制条件"><a href="#动态并行的限制条件" class="headerlink" title="动态并行的限制条件"></a>动态并行的限制条件</h2><p>动态并行只有在计算能力为3.5或更高的设备上才能被支持。通过动态并行调用的内核不能在物理方面独立的设备上启动。动态并行的最大嵌套深度限制为24，但实际上，在每一个新的级别中大多数内核受限于设备运行时系统需要的内存数量。因为为了对每个嵌套层中的父网格和子网格之间进行同步管理，设备运行时需要保留额外的内存。</p>
]]></content>
      <categories>
        <category>cuda基础学习</category>
      </categories>
      <tags>
        <tag>cuda</tag>
        <tag>gpu</tag>
      </tags>
  </entry>
  <entry>
    <title>cuda的进阶学习</title>
    <url>/2022/03/06/cuda%E7%9A%84%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/441146275">[施工中] CUDA GEMM 理论性能分析与 kernel 优化</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/413145211">英伟达GPU架构演进近十年，从费米到安培</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/423992093">CUDA高性能计算经典问题（二）—— 前缀和（Prefix Sum）</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/138668785">处理器和GPU的计算能力如何计算？</a></p>
<p>FFMA理论算力=cuda core <em> 核心频率 </em>2<br>(这里的2表示一个FMA一个时钟周期可以进行2次乘或加的运算)</p>
<p>实际算力=访存比*带宽</p>
<p>关于<a href="https://zhuanlan.zhihu.com/p/441146275">cuda femm</a>中的<a href="https://github.com/Yinghan-Li/YHs_Sample/blob/master/cuda/gemm/sgemm.cu">代码</a>的一些笔记。<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdint&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdlib&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cmath&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">random_init</span><span class="params">(<span class="type">float</span> *data, <span class="type">size_t</span> size)</span> &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; size; ++i) &#123;</span><br><span class="line">        data[i] = <span class="type">float</span>(rand()) / RAND_MAX;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">bool</span> <span class="title function_">check</span><span class="params">(<span class="type">const</span> <span class="type">float</span> *A,</span></span><br><span class="line"><span class="params">           <span class="type">const</span> <span class="type">float</span> *B,</span></span><br><span class="line"><span class="params">           <span class="type">const</span> <span class="type">float</span> *C,</span></span><br><span class="line"><span class="params">           <span class="type">int</span> m, <span class="type">int</span> n, <span class="type">int</span> k)</span> &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; m; ++i) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; n; ++j) &#123;</span><br><span class="line">            <span class="type">float</span> sum = <span class="number">0.f</span>;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> p = <span class="number">0</span>; p &lt; k; ++p) &#123;</span><br><span class="line">                sum += A[i * k + p] * B[j + p * n];</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">std</span>::<span class="built_in">fabs</span>(sum - C[i * n + j]) / <span class="built_in">std</span>::<span class="built_in">fabs</span>(sum) &gt; <span class="number">1e-5</span>f) &#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;C[%d][%d] not match, %f vs %f\n&quot;</span>, i, j, sum, C[i * n + j]);</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__device__ __forceinline__</span><br><span class="line"><span class="type">uint32_t</span> <span class="title function_">smem_u32addr</span><span class="params">(<span class="type">const</span> <span class="type">void</span> *smem_ptr)</span> &#123;</span><br><span class="line">    <span class="type">uint32_t</span> addr;</span><br><span class="line">    <span class="keyword">asm</span> (<span class="string">&quot;&#123;.reg .u64 u64addr;\n&quot;</span></span><br><span class="line">         <span class="string">&quot; cvta.to.shared.u64 u64addr, %1;\n&quot;</span></span><br><span class="line">         <span class="string">&quot; cvt.u32.u64 %0, u64addr;&#125;\n&quot;</span></span><br><span class="line">         : <span class="string">&quot;=r&quot;</span>(addr)</span><br><span class="line">         : <span class="string">&quot;l&quot;</span>(smem_ptr)</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> addr;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__device__ __forceinline__</span><br><span class="line"><span class="type">void</span> <span class="title function_">ldg32_nc</span><span class="params">(<span class="type">float</span> &amp;reg, <span class="type">const</span> <span class="type">void</span> *ptr, <span class="type">bool</span> guard)</span> &#123;</span><br><span class="line">    <span class="keyword">asm</span> <span class="title function_">volatile</span> <span class="params">(</span></span><br><span class="line"><span class="params">        <span class="string">&quot;&#123;.reg .pred p;\n&quot;</span></span></span><br><span class="line"><span class="params">        <span class="string">&quot; setp.ne.b32 p, %2, 0;\n&quot;</span></span></span><br><span class="line"><span class="params">#<span class="keyword">if</span> __CUDACC_VER_MAJOR__ &gt;= <span class="number">11</span> &amp;&amp; __CUDACC_VER_MINOR__ &gt;= <span class="number">4</span> &amp;&amp; \</span></span><br><span class="line"><span class="params">    __CUDA_ARCH__ &gt;= <span class="number">750</span></span></span><br><span class="line"><span class="params">        <span class="string">&quot; @p ld.global.nc.L2::128B.f32 %0, [%1];&#125;\n&quot;</span></span></span><br><span class="line"><span class="params">#<span class="keyword">else</span></span></span><br><span class="line"><span class="params">        <span class="string">&quot; @p ld.global.nc.f32 %0, [%1];&#125;\n&quot;</span></span></span><br><span class="line"><span class="params">#endif</span></span><br><span class="line"><span class="params">        : <span class="string">&quot;=f&quot;</span>(reg)</span></span><br><span class="line"><span class="params">        : <span class="string">&quot;l&quot;</span>(ptr), <span class="string">&quot;r&quot;</span>((<span class="type">int</span>)guard)</span></span><br><span class="line"><span class="params">    )</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__device__ __forceinline__</span><br><span class="line"><span class="type">void</span> <span class="title function_">ldg32_nc_0</span><span class="params">(<span class="type">float</span> &amp;reg, <span class="type">const</span> <span class="type">void</span> *ptr, <span class="type">bool</span> guard)</span> &#123;</span><br><span class="line">    <span class="keyword">asm</span> <span class="title function_">volatile</span> <span class="params">(</span></span><br><span class="line"><span class="params">        <span class="string">&quot;&#123;.reg .pred p;\n&quot;</span></span></span><br><span class="line"><span class="params">        <span class="string">&quot; setp.ne.b32 p, %2, 0;\n&quot;</span></span></span><br><span class="line"><span class="params">        <span class="string">&quot; @!p mov.b32 %0, 0;\n&quot;</span></span></span><br><span class="line"><span class="params">#<span class="keyword">if</span> __CUDACC_VER_MAJOR__ &gt;= <span class="number">11</span> &amp;&amp; __CUDACC_VER_MINOR__ &gt;= <span class="number">4</span> &amp;&amp; \</span></span><br><span class="line"><span class="params">    __CUDA_ARCH__ &gt;= <span class="number">750</span></span></span><br><span class="line"><span class="params">        <span class="string">&quot; @p ld.global.nc.L2::128B.f32 %0, [%1];&#125;\n&quot;</span></span></span><br><span class="line"><span class="params">#<span class="keyword">else</span></span></span><br><span class="line"><span class="params">        <span class="string">&quot; @p ld.global.nc.f32 %0, [%1];&#125;\n&quot;</span></span></span><br><span class="line"><span class="params">#endif</span></span><br><span class="line"><span class="params">        : <span class="string">&quot;=f&quot;</span>(reg)</span></span><br><span class="line"><span class="params">        : <span class="string">&quot;l&quot;</span>(ptr), <span class="string">&quot;r&quot;</span>((<span class="type">int</span>)guard)</span></span><br><span class="line"><span class="params">    )</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__device__ __forceinline__</span><br><span class="line"><span class="type">void</span> <span class="title function_">stg32</span><span class="params">(<span class="type">const</span> <span class="type">float</span> &amp;reg, <span class="type">void</span> *ptr, <span class="type">bool</span> guard)</span> &#123;</span><br><span class="line">    <span class="keyword">asm</span> <span class="title function_">volatile</span> <span class="params">(</span></span><br><span class="line"><span class="params">        <span class="string">&quot;&#123;.reg .pred p;\n&quot;</span></span></span><br><span class="line"><span class="params">        <span class="string">&quot; setp.ne.b32 p, %2, 0;\n&quot;</span></span></span><br><span class="line"><span class="params">        <span class="string">&quot; @p st.global.f32 [%0], %1;&#125;\n&quot;</span></span></span><br><span class="line"><span class="params">        : : <span class="string">&quot;l&quot;</span>(ptr), <span class="string">&quot;f&quot;</span>(reg), <span class="string">&quot;r&quot;</span>((<span class="type">int</span>)guard)</span></span><br><span class="line"><span class="params">    )</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__device__ __forceinline__</span><br><span class="line"><span class="type">void</span> <span class="title function_">lds128</span><span class="params">(<span class="type">float</span> &amp;reg0, <span class="type">float</span> &amp;reg1,</span></span><br><span class="line"><span class="params">            <span class="type">float</span> &amp;reg2, <span class="type">float</span> &amp;reg3,</span></span><br><span class="line"><span class="params">            <span class="type">const</span> <span class="type">uint32_t</span> &amp;addr)</span> &#123;</span><br><span class="line">    <span class="keyword">asm</span> <span class="title function_">volatile</span> <span class="params">(</span></span><br><span class="line"><span class="params">        <span class="string">&quot;ld.shared.v4.f32 &#123;%0, %1, %2, %3&#125;, [%4];\n&quot;</span></span></span><br><span class="line"><span class="params">        : <span class="string">&quot;=f&quot;</span>(reg0), <span class="string">&quot;=f&quot;</span>(reg1), <span class="string">&quot;=f&quot;</span>(reg2), <span class="string">&quot;=f&quot;</span>(reg3)</span></span><br><span class="line"><span class="params">        : <span class="string">&quot;r&quot;</span>(addr)</span></span><br><span class="line"><span class="params">    )</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__device__ __forceinline__</span><br><span class="line"><span class="type">void</span> <span class="title function_">sts32</span><span class="params">(<span class="type">const</span> <span class="type">float</span> &amp;reg, <span class="type">const</span> <span class="type">uint32_t</span> &amp;addr)</span> &#123;</span><br><span class="line">    <span class="keyword">asm</span> <span class="title function_">volatile</span> <span class="params">(</span></span><br><span class="line"><span class="params">        <span class="string">&quot;st.shared.f32 [%0], %1;\n&quot;</span></span></span><br><span class="line"><span class="params">        : : <span class="string">&quot;r&quot;</span>(addr), <span class="string">&quot;f&quot;</span>(reg)</span></span><br><span class="line"><span class="params">    )</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__device__ __forceinline__</span><br><span class="line"><span class="type">void</span> <span class="title function_">sts128</span><span class="params">(<span class="type">const</span> <span class="type">float</span> &amp;reg0, <span class="type">const</span> <span class="type">float</span> &amp;reg1,</span></span><br><span class="line"><span class="params">            <span class="type">const</span> <span class="type">float</span> &amp;reg2, <span class="type">const</span> <span class="type">float</span> &amp;reg3,</span></span><br><span class="line"><span class="params">            <span class="type">const</span> <span class="type">uint32_t</span> &amp;addr)</span> &#123;</span><br><span class="line">    <span class="keyword">asm</span> <span class="title function_">volatile</span> <span class="params">(</span></span><br><span class="line"><span class="params">        <span class="string">&quot;st.shared.v4.f32 [%0], &#123;%1, %2, %3, %4&#125;;\n&quot;</span></span></span><br><span class="line"><span class="params">        : : <span class="string">&quot;r&quot;</span>(addr), <span class="string">&quot;f&quot;</span>(reg0), <span class="string">&quot;f&quot;</span>(reg1), <span class="string">&quot;f&quot;</span>(reg2), <span class="string">&quot;f&quot;</span>(reg3)</span></span><br><span class="line"><span class="params">    )</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">StgFrag</span> &#123;</span></span><br><span class="line">    <span class="type">float</span> data[<span class="number">4</span>][<span class="number">4</span>];</span><br><span class="line"></span><br><span class="line">    __device__ __forceinline__</span><br><span class="line">    <span class="title function_">StgFrag</span><span class="params">(<span class="type">const</span> <span class="type">float</span> (&amp;C_frag)[<span class="number">8</span>][<span class="number">8</span>], <span class="type">int</span> tile_x, <span class="type">int</span> tile_y)</span> &#123;</span><br><span class="line">        <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; ++i) &#123;</span><br><span class="line">            <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; <span class="number">4</span>; ++j) &#123;</span><br><span class="line">                data[i][j] = C_frag[tile_y * <span class="number">4</span> + i][tile_x * <span class="number">4</span> + j];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">__device__ __noinline__</span><br><span class="line"><span class="type">void</span> <span class="title function_">C_tile_wb</span><span class="params">(StgFrag C_frag,</span></span><br><span class="line"><span class="params">               <span class="type">float</span> *C_stg_ptr,</span></span><br><span class="line"><span class="params">               <span class="type">const</span> <span class="type">float</span> *C_lds_ptr,</span></span><br><span class="line"><span class="params">               <span class="type">uint32_t</span> C_sts_addr,</span></span><br><span class="line"><span class="params">               <span class="type">uint32_t</span> m,</span></span><br><span class="line"><span class="params">               <span class="type">uint32_t</span> n,</span></span><br><span class="line"><span class="params">               <span class="type">uint32_t</span> m_idx,</span></span><br><span class="line"><span class="params">               <span class="type">uint32_t</span> n_idx)</span> &#123;</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; ++i) &#123;</span><br><span class="line">        sts128(C_frag.data[i][<span class="number">0</span>],</span><br><span class="line">               C_frag.data[i][<span class="number">1</span>],</span><br><span class="line">               C_frag.data[i][<span class="number">2</span>],</span><br><span class="line">               C_frag.data[i][<span class="number">3</span>],</span><br><span class="line">               C_sts_addr + i * <span class="number">8</span> * <span class="keyword">sizeof</span>(float4));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="type">uint32_t</span> m_guard = m &lt; m_idx ? <span class="number">0</span> : m - m_idx;</span><br><span class="line"></span><br><span class="line">    <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">16</span>; ++i) &#123;</span><br><span class="line">        stg32(C_lds_ptr[i * <span class="number">32</span>],</span><br><span class="line">              C_stg_ptr + i * n,</span><br><span class="line">              i &lt; m_guard &amp;&amp; n_idx &lt; n);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * matrix A, B and C: row-major</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * mma block:</span></span><br><span class="line"><span class="comment"> * thread block tile: m128n128k8</span></span><br><span class="line"><span class="comment"> * warp tile: m32n64k8</span></span><br><span class="line"><span class="comment"> * thread tile: m8n8k8</span></span><br><span class="line"><span class="comment"> * thread fragment:</span></span><br><span class="line"><span class="comment"> *     matrixA: 8x1 FP32</span></span><br><span class="line"><span class="comment"> *     matrixB: 1x8 FP32</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * ----------------------------------------------------------------</span></span><br><span class="line"><span class="comment"> * thread block tile map:</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *                                128</span></span><br><span class="line"><span class="comment"> *                    --|---------------------|</span></span><br><span class="line"><span class="comment"> *             B_tile  8|                     |</span></span><br><span class="line"><span class="comment"> *                    --|---------------------|</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *  A_tile   | 8 |      |    64    |</span></span><br><span class="line"><span class="comment"> *         --|---|    --|----------|----------|</span></span><br><span class="line"><span class="comment"> *           |   |    32|  warp_0  |  warp_1  |</span></span><br><span class="line"><span class="comment"> *           |   |    --|----------|----------|</span></span><br><span class="line"><span class="comment"> *           |   |      |  warp_2  |  warp_3  |</span></span><br><span class="line"><span class="comment"> *        128|   |      |----------|----------|</span></span><br><span class="line"><span class="comment"> *           |   |      |  warp_4  |  warp_5  |</span></span><br><span class="line"><span class="comment"> *           |   |      |----------|----------|</span></span><br><span class="line"><span class="comment"> *           |   |      |  warp_6  |  warp_7  |</span></span><br><span class="line"><span class="comment"> *         --|---|      |----------|----------|</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * ----------------------------------------------------------------</span></span><br><span class="line"><span class="comment"> * warp tile map:</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &#x27;z&#x27; thread map to avoid LDS.128 shared memory broadcast limitation.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *              |              32               ||</span></span><br><span class="line"><span class="comment"> *     B_frag --|---|---|---|---|---|---|---|---||---|---|---|---|---|---|---|---|</span></span><br><span class="line"><span class="comment"> *             1|///|   |   |   |   |   |   |   ||///|   |   |   |   |   |   |   |</span></span><br><span class="line"><span class="comment"> *            --|---|---|---|---|---|---|---|---||---|---|---|---|---|---|---|---|</span></span><br><span class="line"><span class="comment"> * A_frag       | 4 |                           ||</span></span><br><span class="line"><span class="comment"> *    | 1 |                                     ||</span></span><br><span class="line"><span class="comment"> *  --|---|--   |---|---|---|---|---|---|---|---||---|---------------------------|</span></span><br><span class="line"><span class="comment"> *    |///|4    |t0 |t2 |t4 |t6 |t8 |t10|t12|t14||t0 |                           |</span></span><br><span class="line"><span class="comment"> *    |---|--   |---|---|---|---|---|---|---|---||---|                           |</span></span><br><span class="line"><span class="comment"> *    |   |     |t1 |t3 |t5 |t7 |t9 |t11|t13|t15||                               |</span></span><br><span class="line"><span class="comment"> *  16|---|     |---|---|---|---|---|---|---|---||                               |</span></span><br><span class="line"><span class="comment"> *    |   |     |t16|t18|t20|t22|t24|t26|t28|t30||                               |</span></span><br><span class="line"><span class="comment"> *    |---|     |---|---|---|---|---|---|---|---||                               |</span></span><br><span class="line"><span class="comment"> *    |   |     |t17|t19|t21|t23|t25|t27|t29|t31||                               |</span></span><br><span class="line"><span class="comment"> *  ==|===|=====|===|===|===|===|===|===|===|===||===|============================</span></span><br><span class="line"><span class="comment"> *    |///|     |t0 |                           ||t0 |                           |</span></span><br><span class="line"><span class="comment"> *    |---|     |---|                           ||---|                           |</span></span><br><span class="line"><span class="comment"> *    |   |     |                               ||                               |</span></span><br><span class="line"><span class="comment"> *    |---|     |                               ||                               |</span></span><br><span class="line"><span class="comment"> *    |   |     |                               ||                               |</span></span><br><span class="line"><span class="comment"> *    |---|     |                               ||                               |</span></span><br><span class="line"><span class="comment"> *    |   |     |                               ||                               |</span></span><br><span class="line"><span class="comment"> *    |---|     |-------------------------------||-------------------------------|</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">__global__ __launch_bounds__(<span class="number">256</span>, <span class="number">2</span>)<span class="comment">//__launch_bounds__(maxThreadsPerBlock, minBlocksPerMultiprocessor)</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">sgemm_128x128x8_kernel</span><span class="params">(<span class="type">const</span> <span class="type">float</span> *A,</span></span><br><span class="line"><span class="params">                            <span class="type">const</span> <span class="type">float</span> *B,</span></span><br><span class="line"><span class="params">                            <span class="type">float</span> *C,</span></span><br><span class="line"><span class="params">                            <span class="type">uint32_t</span> m,</span></span><br><span class="line"><span class="params">                            <span class="type">uint32_t</span> n,</span></span><br><span class="line"><span class="params">                            <span class="type">uint32_t</span> k,</span></span><br><span class="line"><span class="params">                            <span class="type">uint32_t</span> A_ldg_step,    <span class="comment">// k * sizeof(float)</span></span></span><br><span class="line"><span class="params">                            <span class="type">uint32_t</span> B_ldg_step)</span> &#123;  <span class="comment">// n * sizeof(float) * 8</span></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * matrix A &amp; B thread block tile shared memory (double buffer)</span></span><br><span class="line"><span class="comment">     * matrix A: 132 * 8 * 4Byte/item * double buffer = 4.125KB * 2</span></span><br><span class="line"><span class="comment">     * matrix B: 128 * 8 * 4Byte/item * double buffer = 8KB</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * for double buffer faster switch, A_smem requires 8KB * 2 shared memory</span></span><br><span class="line"><span class="comment">     * and 16KB aligned, B_smem should be 8KB aligned, then the double buffer</span></span><br><span class="line"><span class="comment">     * can be switched by only 1 xor instruction:</span></span><br><span class="line"><span class="comment">     *     (uint32_t &amp;)A_smem ^= 0x2000;</span></span><br><span class="line"><span class="comment">     *     (uint32_t &amp;)B_smem ^= 0x1000;</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    __shared__ __align__(<span class="number">16</span> * <span class="number">1024</span>) <span class="type">char</span> smem[<span class="number">24</span> * <span class="number">1024</span>];</span><br><span class="line">    <span class="type">float</span> *A_smem = reinterpret_cast&lt;<span class="type">float</span> *&gt;(smem);</span><br><span class="line">    <span class="type">float</span> *B_smem = reinterpret_cast&lt;<span class="type">float</span> *&gt;(smem + <span class="number">16</span> * <span class="number">1024</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// A, B and C register fragment</span></span><br><span class="line">    <span class="type">float</span> A_frag[<span class="number">2</span>][<span class="number">8</span>];</span><br><span class="line">    <span class="type">float</span> B_frag[<span class="number">2</span>][<span class="number">8</span>];</span><br><span class="line">    <span class="type">float</span> C_frag[<span class="number">8</span>][<span class="number">8</span>];</span><br><span class="line">    <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">8</span>; ++i) &#123;</span><br><span class="line">        <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; <span class="number">8</span>; ++j) &#123;</span><br><span class="line">            C_frag[i][j] = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">uint32_t</span> lane_id = threadIdx.x % <span class="number">32</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">uint32_t</span> warp_id = threadIdx.x / <span class="number">32</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4x8 threads each warp for FFMA</span></span><br><span class="line">    <span class="type">const</span> <span class="type">uint32_t</span> mma_tid_x = (lane_id / <span class="number">2</span>) % <span class="number">8</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">uint32_t</span> mma_tid_y = (lane_id / <span class="number">16</span>) * <span class="number">2</span> + (lane_id % <span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// A_tile &amp; B_tile ldg pointer</span></span><br><span class="line">    <span class="type">const</span> <span class="type">char</span> *A_ldg_ptr = (<span class="type">const</span> <span class="type">char</span> *)(</span><br><span class="line">        A + (blockIdx.y * <span class="number">128</span> + threadIdx.x / <span class="number">8</span> * <span class="number">4</span>) * k + threadIdx.x % <span class="number">8</span>);</span><br><span class="line">    <span class="type">const</span> <span class="type">char</span> *B_ldg_ptr = (<span class="type">const</span> <span class="type">char</span> *)(</span><br><span class="line">        B + (threadIdx.x / <span class="number">32</span>) * n + blockIdx.x * <span class="number">128</span> + threadIdx.x % <span class="number">32</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// A_tile &amp; B_tile sts/lds pointer</span></span><br><span class="line">    <span class="comment">// using uint32_t pointer for faster double buffer switch</span></span><br><span class="line">    <span class="type">uint32_t</span> A_sts_addr = smem_u32addr(</span><br><span class="line">        A_smem + (threadIdx.x % <span class="number">8</span>) * <span class="number">132</span> + (threadIdx.x / <span class="number">8</span>) * <span class="number">4</span>);</span><br><span class="line">    <span class="type">uint32_t</span> B_sts_addr = smem_u32addr(</span><br><span class="line">        B_smem + (threadIdx.x / <span class="number">32</span>) * <span class="number">128</span> + (threadIdx.x % <span class="number">32</span>));</span><br><span class="line"></span><br><span class="line">    <span class="type">uint32_t</span> A_lds_addr = smem_u32addr(</span><br><span class="line">        A_smem + (warp_id / <span class="number">2</span>) * <span class="number">32</span> + mma_tid_y * <span class="number">4</span>);</span><br><span class="line">    <span class="type">uint32_t</span> B_lds_addr = smem_u32addr(</span><br><span class="line">        B_smem + (warp_id % <span class="number">2</span>) * <span class="number">64</span> + mma_tid_x * <span class="number">4</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ldg_guard to avoid LDG out of bound</span></span><br><span class="line">    <span class="type">uint32_t</span> A_ldg_guard = <span class="number">0</span>;</span><br><span class="line">    <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; ++i) &#123;</span><br><span class="line">        <span class="type">int</span> m_idx = blockIdx.y * <span class="number">128</span> + threadIdx.x / <span class="number">8</span> * <span class="number">4</span> + i;</span><br><span class="line">        <span class="keyword">if</span> (m_idx &lt; m) &#123;</span><br><span class="line">            A_ldg_guard |= (<span class="number">1u</span> &lt;&lt; i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">uint32_t</span> B_ldg_guard = <span class="number">0</span>;</span><br><span class="line">    <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; ++i) &#123;</span><br><span class="line">        <span class="type">int</span> n_idx = blockIdx.x * <span class="number">128</span> + threadIdx.x % <span class="number">32</span> + i * <span class="number">32</span>;</span><br><span class="line">        <span class="keyword">if</span> (n_idx &lt; n) &#123;</span><br><span class="line">            B_ldg_guard |= (<span class="number">1u</span> &lt;&lt; i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> A_ldg_reg[<span class="number">4</span>];</span><br><span class="line">    <span class="type">float</span> B_ldg_reg[<span class="number">4</span>];</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1&#x27;st A&amp;B tile loaded before the k_tile loop</span></span><br><span class="line">    <span class="type">uint32_t</span> k_tiles = (k + <span class="number">7</span>) / <span class="number">8</span> - <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// load 1&#x27;st tile to shared memory</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">uint32_t</span> first_k_tile = k - k_tiles * <span class="number">8</span>;</span><br><span class="line"></span><br><span class="line">        <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; ++i) &#123;</span><br><span class="line">            <span class="type">bool</span> guard = (A_ldg_guard &amp; (<span class="number">1u</span> &lt;&lt; i)) != <span class="number">0</span> &amp;&amp;</span><br><span class="line">                         threadIdx.x % <span class="number">8</span> &lt; first_k_tile;</span><br><span class="line">            ldg32_nc_0(A_ldg_reg[i],</span><br><span class="line">                       A_ldg_ptr + i * A_ldg_step,</span><br><span class="line">                       guard);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        sts128(A_ldg_reg[<span class="number">0</span>], A_ldg_reg[<span class="number">1</span>], A_ldg_reg[<span class="number">2</span>], A_ldg_reg[<span class="number">3</span>],</span><br><span class="line">               A_sts_addr);</span><br><span class="line"></span><br><span class="line">        <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; ++i) &#123;</span><br><span class="line">            <span class="type">bool</span> guard = (B_ldg_guard &amp; (<span class="number">1u</span> &lt;&lt; i)) != <span class="number">0</span> &amp;&amp;</span><br><span class="line">                         threadIdx.x / <span class="number">32</span> &lt; first_k_tile;</span><br><span class="line">            ldg32_nc_0(B_ldg_reg[i],</span><br><span class="line">                       B_ldg_ptr + i * <span class="number">32</span> * <span class="keyword">sizeof</span>(<span class="type">float</span>),</span><br><span class="line">                       guard);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; ++i) &#123;</span><br><span class="line">            sts32(B_ldg_reg[i], B_sts_addr + i * <span class="number">32</span> * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        __syncthreads();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// switch double buffer</span></span><br><span class="line">        A_sts_addr ^= <span class="number">0x2000</span>;</span><br><span class="line">        B_sts_addr ^= <span class="number">0x1000</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// ldg pointer for next tile</span></span><br><span class="line">        A_ldg_ptr += first_k_tile * <span class="keyword">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">        B_ldg_ptr += n * first_k_tile * <span class="keyword">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// load 1&#x27;st fragment</span></span><br><span class="line">    lds128(A_frag[<span class="number">0</span>][<span class="number">0</span>], A_frag[<span class="number">0</span>][<span class="number">1</span>], A_frag[<span class="number">0</span>][<span class="number">2</span>], A_frag[<span class="number">0</span>][<span class="number">3</span>],</span><br><span class="line">           A_lds_addr);</span><br><span class="line">    lds128(A_frag[<span class="number">0</span>][<span class="number">4</span>], A_frag[<span class="number">0</span>][<span class="number">5</span>], A_frag[<span class="number">0</span>][<span class="number">6</span>], A_frag[<span class="number">0</span>][<span class="number">7</span>],</span><br><span class="line">           A_lds_addr + <span class="number">16</span> * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    lds128(B_frag[<span class="number">0</span>][<span class="number">0</span>], B_frag[<span class="number">0</span>][<span class="number">1</span>], B_frag[<span class="number">0</span>][<span class="number">2</span>], B_frag[<span class="number">0</span>][<span class="number">3</span>],</span><br><span class="line">           B_lds_addr);</span><br><span class="line">    lds128(B_frag[<span class="number">0</span>][<span class="number">4</span>], B_frag[<span class="number">0</span>][<span class="number">5</span>], B_frag[<span class="number">0</span>][<span class="number">6</span>], B_frag[<span class="number">0</span>][<span class="number">7</span>],</span><br><span class="line">           B_lds_addr + <span class="number">32</span> * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// k_tiles loop</span></span><br><span class="line">    <span class="keyword">for</span> (; k_tiles &gt; <span class="number">0</span>; --k_tiles) &#123;</span><br><span class="line">        <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> k_frag = <span class="number">0</span>; k_frag &lt; <span class="number">8</span>; ++k_frag) &#123;</span><br><span class="line">            <span class="comment">// store next A&amp;B tile to shared memory</span></span><br><span class="line">            <span class="keyword">if</span> (k_frag == <span class="number">7</span>) &#123;</span><br><span class="line">                sts128(A_ldg_reg[<span class="number">0</span>], A_ldg_reg[<span class="number">1</span>], A_ldg_reg[<span class="number">2</span>], A_ldg_reg[<span class="number">3</span>],</span><br><span class="line">                       A_sts_addr);</span><br><span class="line">                <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; ++i) &#123;</span><br><span class="line">                    sts32(B_ldg_reg[i], B_sts_addr + i * <span class="number">32</span> * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                __syncthreads();</span><br><span class="line"></span><br><span class="line">                <span class="comment">// switch double buffer</span></span><br><span class="line">                A_lds_addr ^= <span class="number">0x2000</span>;</span><br><span class="line">                B_lds_addr ^= <span class="number">0x1000</span>;</span><br><span class="line">                A_sts_addr ^= <span class="number">0x2000</span>;</span><br><span class="line">                B_sts_addr ^= <span class="number">0x1000</span>;</span><br><span class="line"></span><br><span class="line">                <span class="comment">// ldg pointer for next tile</span></span><br><span class="line">                A_ldg_ptr += <span class="number">8</span> * <span class="keyword">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">                B_ldg_ptr += B_ldg_step;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// load next A&amp;B fragment from shared memory to register</span></span><br><span class="line">            lds128(A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">0</span>],</span><br><span class="line">                   A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">1</span>],</span><br><span class="line">                   A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">2</span>],</span><br><span class="line">                   A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">3</span>],</span><br><span class="line">                   A_lds_addr + (k_frag + <span class="number">1</span>) % <span class="number">8</span> * <span class="number">132</span> * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            lds128(A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">4</span>],</span><br><span class="line">                   A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">5</span>],</span><br><span class="line">                   A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">6</span>],</span><br><span class="line">                   A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">7</span>],</span><br><span class="line">                   A_lds_addr + ((k_frag + <span class="number">1</span>) % <span class="number">8</span> * <span class="number">132</span> + <span class="number">16</span>) * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            lds128(B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">0</span>],</span><br><span class="line">                   B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">1</span>],</span><br><span class="line">                   B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">2</span>],</span><br><span class="line">                   B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">3</span>],</span><br><span class="line">                   B_lds_addr + (k_frag + <span class="number">1</span>) % <span class="number">8</span> * <span class="number">128</span> * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            lds128(B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">4</span>],</span><br><span class="line">                   B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">5</span>],</span><br><span class="line">                   B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">6</span>],</span><br><span class="line">                   B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">7</span>],</span><br><span class="line">                   B_lds_addr + ((k_frag + <span class="number">1</span>) % <span class="number">8</span> * <span class="number">128</span> + <span class="number">32</span>) * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// load next A&amp;B tile</span></span><br><span class="line">            <span class="keyword">if</span> (k_frag == <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; ++i) &#123;</span><br><span class="line">                    ldg32_nc(A_ldg_reg[i],</span><br><span class="line">                             A_ldg_ptr + i * A_ldg_step,</span><br><span class="line">                             (A_ldg_guard &amp; (<span class="number">1u</span> &lt;&lt; i)) != <span class="number">0</span>);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; ++i) &#123;</span><br><span class="line">                    ldg32_nc(B_ldg_reg[i],</span><br><span class="line">                             B_ldg_ptr + i * <span class="number">32</span> * <span class="keyword">sizeof</span>(<span class="type">float</span>),</span><br><span class="line">                             (B_ldg_guard &amp; (<span class="number">1u</span> &lt;&lt; i)) != <span class="number">0</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// FFMA loop</span></span><br><span class="line">            <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">8</span>; ++i) &#123;</span><br><span class="line">                <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; <span class="number">8</span>; ++j) &#123;</span><br><span class="line">                    C_frag[i][j] += A_frag[k_frag % <span class="number">2</span>][i] *</span><br><span class="line">                                    B_frag[k_frag % <span class="number">2</span>][j];</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// FFMA for the last tile</span></span><br><span class="line">    <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> k_frag = <span class="number">0</span>; k_frag &lt; <span class="number">8</span>; ++k_frag) &#123;</span><br><span class="line">        <span class="keyword">if</span> (k_frag &lt; <span class="number">7</span>) &#123;</span><br><span class="line">            <span class="comment">// load next A&amp;B fragment from shared memory to register</span></span><br><span class="line">            lds128(A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">0</span>],</span><br><span class="line">                   A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">1</span>],</span><br><span class="line">                   A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">2</span>],</span><br><span class="line">                   A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">3</span>],</span><br><span class="line">                   A_lds_addr + (k_frag + <span class="number">1</span>) % <span class="number">8</span> * <span class="number">132</span> * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            lds128(A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">4</span>],</span><br><span class="line">                   A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">5</span>],</span><br><span class="line">                   A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">6</span>],</span><br><span class="line">                   A_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">7</span>],</span><br><span class="line">                   A_lds_addr + ((k_frag + <span class="number">1</span>) % <span class="number">8</span> * <span class="number">132</span> + <span class="number">16</span>) * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            lds128(B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">0</span>],</span><br><span class="line">                   B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">1</span>],</span><br><span class="line">                   B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">2</span>],</span><br><span class="line">                   B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">3</span>],</span><br><span class="line">                   B_lds_addr + (k_frag + <span class="number">1</span>) % <span class="number">8</span> * <span class="number">128</span> * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            lds128(B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">4</span>],</span><br><span class="line">                   B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">5</span>],</span><br><span class="line">                   B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">6</span>],</span><br><span class="line">                   B_frag[(k_frag + <span class="number">1</span>) % <span class="number">2</span>][<span class="number">7</span>],</span><br><span class="line">                   B_lds_addr + ((k_frag + <span class="number">1</span>) % <span class="number">8</span> * <span class="number">128</span> + <span class="number">32</span>) * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// FFMA loop</span></span><br><span class="line">        <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">8</span>; ++i) &#123;</span><br><span class="line">            <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; <span class="number">8</span>; ++j) &#123;</span><br><span class="line">                C_frag[i][j] += A_frag[k_frag % <span class="number">2</span>][i] *</span><br><span class="line">                                B_frag[k_frag % <span class="number">2</span>][j];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// C_tile write back, reuse A&amp;B tile shared memory buffer</span></span><br><span class="line">    <span class="type">uint32_t</span> C_sts_addr = smem_u32addr((float4 *)(smem + warp_id * <span class="number">2048</span>) +</span><br><span class="line">                                       mma_tid_y * <span class="number">4</span> * <span class="number">8</span> + mma_tid_x);</span><br><span class="line">    <span class="type">const</span> <span class="type">float</span> *C_lds_ptr = (<span class="type">float</span> *)(smem + warp_id * <span class="number">2048</span>) + lane_id;</span><br><span class="line"></span><br><span class="line">    <span class="type">uint32_t</span> m_idx = blockIdx.y * <span class="number">128</span> + warp_id / <span class="number">2</span> * <span class="number">32</span>;</span><br><span class="line">    <span class="type">uint32_t</span> n_idx = blockIdx.x * <span class="number">128</span> + warp_id % <span class="number">2</span> * <span class="number">64</span> + lane_id;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> *C_stg_ptr = C + m_idx * n + n_idx;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (m_idx &gt;= m) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (m_idx + <span class="number">32</span> &lt;= m) &#123;</span><br><span class="line">        <span class="type">uint32_t</span> n_guard = n &lt; n_idx ? <span class="number">0</span> : n - n_idx;</span><br><span class="line"></span><br><span class="line">        <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; ++i) &#123;</span><br><span class="line">            <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; <span class="number">2</span>; ++j) &#123;</span><br><span class="line">                __syncthreads();</span><br><span class="line"></span><br><span class="line">                <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> p = <span class="number">0</span>; p &lt; <span class="number">4</span>; ++p) &#123;</span><br><span class="line">                    sts128(C_frag[i * <span class="number">4</span> + p][j * <span class="number">4</span>],</span><br><span class="line">                           C_frag[i * <span class="number">4</span> + p][j * <span class="number">4</span> + <span class="number">1</span>],</span><br><span class="line">                           C_frag[i * <span class="number">4</span> + p][j * <span class="number">4</span> + <span class="number">2</span>],</span><br><span class="line">                           C_frag[i * <span class="number">4</span> + p][j * <span class="number">4</span> + <span class="number">3</span>],</span><br><span class="line">                           C_sts_addr + p * <span class="number">8</span> * <span class="keyword">sizeof</span>(float4));</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                __syncthreads();</span><br><span class="line"></span><br><span class="line">                <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> p = <span class="number">0</span>; p &lt; <span class="number">16</span>; ++p) &#123;</span><br><span class="line">                    stg32(C_lds_ptr[p * <span class="number">32</span>],</span><br><span class="line">                          C_stg_ptr + (i * <span class="number">16</span> + p) * n + j * <span class="number">32</span>,</span><br><span class="line">                          j * <span class="number">32</span> &lt; n_guard);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; ++i) &#123;</span><br><span class="line">            <span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; <span class="number">2</span>; ++j) &#123;</span><br><span class="line">                StgFrag stg_frag(C_frag, j, i);</span><br><span class="line"></span><br><span class="line">                C_tile_wb(stg_frag,</span><br><span class="line">                          C_stg_ptr + i * <span class="number">16</span> * n + j * <span class="number">32</span>,</span><br><span class="line">                          C_lds_ptr,</span><br><span class="line">                          C_sts_addr,</span><br><span class="line">                          m,</span><br><span class="line">                          n,</span><br><span class="line">                          m_idx + i * <span class="number">16</span>,</span><br><span class="line">                          n_idx + j * <span class="number">32</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">int</span> m = <span class="number">5120</span>;</span><br><span class="line">    <span class="type">int</span> n = <span class="number">4096</span>;</span><br><span class="line">    <span class="type">int</span> k = <span class="number">4096</span>;</span><br><span class="line">    <span class="type">int</span> n_iter = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> *h_A, *h_B, *h_C;</span><br><span class="line">    cudaMallocHost(&amp;h_A, m * k * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    cudaMallocHost(&amp;h_B, k * n * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    cudaMallocHost(&amp;h_C, m * n * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    random_init(h_A, m * k);</span><br><span class="line">    random_init(h_B, k * n);</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> *d_A, *d_B, *d_C;</span><br><span class="line">    cudaMalloc(&amp;d_A, m * k * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    cudaMalloc(&amp;d_B, k * n * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    cudaMalloc(&amp;d_C, m * n * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line"></span><br><span class="line">    cudaMemcpy(d_A, h_A, m * k * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyDefault);</span><br><span class="line">    cudaMemcpy(d_B, h_B, k * n * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyDefault);</span><br><span class="line"></span><br><span class="line">    cudaEvent_t start, end;</span><br><span class="line">    cudaEventCreate(&amp;start);</span><br><span class="line">    cudaEventCreate(&amp;end);</span><br><span class="line"></span><br><span class="line">    dim3 <span class="title function_">grid</span><span class="params">((n + <span class="number">127</span>) / <span class="number">128</span>, (m + <span class="number">127</span>) / <span class="number">128</span>)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// warmup</span></span><br><span class="line">    sgemm_128x128x8_kernel&lt;&lt;&lt;grid, <span class="number">256</span>&gt;&gt;&gt;(</span><br><span class="line">        d_A, d_B, d_C, m, n, k, k * <span class="keyword">sizeof</span>(<span class="type">float</span>), n * <span class="keyword">sizeof</span>(<span class="type">float</span>) * <span class="number">8</span>);</span><br><span class="line"></span><br><span class="line">    cudaEventRecord(start);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n_iter; ++i) &#123;</span><br><span class="line">        sgemm_128x128x8_kernel&lt;&lt;&lt;grid, <span class="number">256</span>&gt;&gt;&gt;(</span><br><span class="line">            d_A, d_B, d_C, m, n, k, k * <span class="keyword">sizeof</span>(<span class="type">float</span>), n * <span class="keyword">sizeof</span>(<span class="type">float</span>) * <span class="number">8</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    cudaEventRecord(end);</span><br><span class="line">    cudaEventSynchronize(end);</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> ms;</span><br><span class="line">    cudaEventElapsedTime(&amp;ms, start, end);</span><br><span class="line">    cudaEventDestroy(start);</span><br><span class="line">    cudaEventDestroy(end);</span><br><span class="line"></span><br><span class="line">    <span class="type">long</span> workload = n_iter * <span class="type">long</span>(m) * n * k * <span class="number">2</span>;</span><br><span class="line">    <span class="type">double</span> gflops = (<span class="type">double</span>(workload) / <span class="number">1e9</span>) / (<span class="type">double</span>(ms) / <span class="number">1e3</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Performance: %fGFLOPS\n&quot;</span>, gflops);</span><br><span class="line"></span><br><span class="line">    cudaMemcpy(h_C, d_C, m * n * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyDefault);</span><br><span class="line"></span><br><span class="line">    <span class="type">bool</span> chk = check(h_A, h_B, h_C, m, n, k);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Matrix_C check: %s\n&quot;</span>, chk ? <span class="string">&quot;OK&quot;</span> : <span class="string">&quot;Failed&quot;</span>);</span><br><span class="line"></span><br><span class="line">    cudaFree(d_A);</span><br><span class="line">    cudaFree(d_B);</span><br><span class="line">    cudaFree(d_C);</span><br><span class="line">    cudaFreeHost(h_A);</span><br><span class="line">    cudaFreeHost(h_B);</span><br><span class="line">    cudaFreeHost(h_C);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>cuda基础学习</category>
      </categories>
      <tags>
        <tag>cuda</tag>
        <tag>gpu</tag>
      </tags>
  </entry>
  <entry>
    <title>online CP decomposition</title>
    <url>/2022/05/15/online-CP-decomposition/</url>
    <content><![CDATA[<h1 id="类似知识"><a href="#类似知识" class="headerlink" title="类似知识"></a>类似知识</h1><h2 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h2><p>待写</p>
<h2 id="SVD"><a href="#SVD" class="headerlink" title="SVD"></a>SVD</h2><p>待写</p>
<h1 id="Tensor-Decomposition"><a href="#Tensor-Decomposition" class="headerlink" title="Tensor Decomposition"></a>Tensor Decomposition</h1><p>用于feature extraction、dimensionality reduction和knowledge discovery。随着时间的变化，张量的数据可能增加、减少或者修改在他任何的维度上。现实生活中最常用的动态张量就是随着时间变化的数据，而其它的维度保持不变。这种张量称为 online tensors, tensor streams incremental tensors.<br>在大规模的online tensor中，找到其分解结果是很困难的，他的难点主要是</p>
<ul>
<li>online tensors are growing with time,他的整体大小其实是没有限制的。TD 需要高效和可扩展，从时间和空间来看。</li>
<li>高数据生成速率需要分解方法提供实时或接近实时的性能。</li>
</ul>
<h1 id="Notation-and-basic-operations"><a href="#Notation-and-basic-operations" class="headerlink" title="Notation and basic operations"></a>Notation and basic operations</h1><div class="table-container">
<table>
<thead>
<tr>
<th>symbol</th>
<th>definition</th>
</tr>
</thead>
<tbody>
<tr>
<td>$A^{T}$</td>
<td>转置 transpose</td>
</tr>
<tr>
<td>$A^{-1}$</td>
<td>逆 inverse</td>
</tr>
<tr>
<td>$A^{\dagger}$</td>
<td>Moore-Penrose pseudoinverse</td>
</tr>
<tr>
<td>$\lVert A\rVert$</td>
<td>frobenius norm</td>
</tr>
<tr>
<td>$\odot$</td>
<td>khatri-rao product</td>
</tr>
<tr>
<td>$\otimes$</td>
<td>hadamard product</td>
</tr>
<tr>
<td>$X_{(n)}$</td>
<td>张量的mode-n展开</td>
</tr>
</tbody>
</table>
</div>
<h1 id="预知识"><a href="#预知识" class="headerlink" title="预知识"></a>预知识</h1><h2 id="CP分解"><a href="#CP分解" class="headerlink" title="CP分解"></a>CP分解</h2><p>cp分解被广泛用于探索多维数据的潜在结构。给定一个N阶的张量$\mathcal{X}\in \mathbb{R}^{I_1\times \cdots \times I_N}$，CP分解近似这个张量通过N个loading 矩阵，因此</p>
<script type="math/tex; mode=display">
\begin{equation}
X_{(n)}\approx A^{(n)}(A^{(N)}\odot \cdots A^{(n+1)}\odot A^{(n-1)}\cdots A^{(1)})^T  =A^{(n)}(\odot^N_{i\neq n}A^{(i)})^T=[A^{(1)},\cdots,A^{(N)}] 
\end{equation}</script><p>其中$[\cdot]$定义为cp分解符号。<br>为了找到CP分解的结果，目标函数是最小化估计误差 $\mathcal{L}$，定义为</p>
<script type="math/tex; mode=display">
\mathcal{L}=\frac{1}{2}\| X_{(n)}-A^{(n)}(\odot^N_{i\neq n}A^{(i)})^T\|^2</script><p>但是直接最小化$\mathcal{L}$很困难，因为$\mathcal{L}$关于$A^{(1)},\cdots,A^{(N)}$是nonconvex的，因此常用的办法是使用ALS，通过固定n-th矩阵，交替最小化，此时$\mathcal{X}$关于$A^{(n)}$是convex的，此时</p>
<script type="math/tex; mode=display">
A^{(n)}\gets argmin_{A^{(n)}} \frac{1}{2}\| X_{(n)}-A^{(n)}(\odot^N_{i\neq n}A^{(i)})^T\|^2 \tag{2}</script><h2 id="online-CP分解"><a href="#online-CP分解" class="headerlink" title="online CP分解"></a>online CP分解</h2><p>给出一个三维的online tensor$\mathcal{X}\in \mathbb{X}^{I\times J\times (t_{old}+t_{new})}$，这个$\mathcal{X}$是通过对$\mathcal{X}_{old}\in \mathbb{R}^{I\times J\times t_{old}}$的最后一个mode进行追加$\mathcal{X}_{new}\in \mathbb{R}^{I\times J\times t_{new}}$.通常追加的张量很小，因此假设$\mathcal{X}_{new}\ll \mathcal{X}_{old}$. $\mathcal{X}_{old}$的cp分解写作$[A_{old},B_{old},C_{old}]$.目标是找到$\mathcal{X}$的cp分解$[A,B,C]$.<br>针对三阶张量</p>
<script type="math/tex; mode=display">
C\gets argmin_{C} \frac{1}{2}\| X_{(3)}-C(A\odot B)^T\|^2 \tag{2}</script><p>下面介绍一个现有的online cp分解的方法<br><strong>SDT and RLST</strong>  这两种方法都是将online张量分解问题转换成增量矩阵分解问题，令$D=A\odot B$, 因此公式(1)可以被写成$X_{(3)}=CD^T$，问题就转变为如何去估计C和D。这两种方法不同之处在于计算C和D。<br>[//]: #  SDT选择SVD来进行$ X_{old(3)}=U_{old}\sum_{old}V^T_{old}$，这时总有一个矩阵$W_{old}$使得$C_{old}=U_{old}W^{-1}_{old}$, $D_{old}=V_{old}\sum_{old}W_{old}^T$.同理得到，可以找到一个矩阵$W$，使得$C=UW^{-1}$, $D=V\sum W^T$,其中$U\sum V^T$是$X_{(3)}$的SVD分解。作者假设$D$和$D_{old}$只有微小的区别，因此</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1]Zhou S, Vinh N X, Bailey J, et al. Accelerating Online CP Decompositions for Higher Order Tensors[A]. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining[C]. New York, NY, USA: Association for Computing Machinery, 2016: 1375–1384.</p>
]]></content>
      <categories>
        <category>张量分解</category>
      </categories>
      <tags>
        <tag>tensor</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>ptx的学习</title>
    <url>/2022/04/14/ptx%E7%9A%84%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h1 id="inline-ptx-assembly-in-CUDA"><a href="#inline-ptx-assembly-in-CUDA" class="headerlink" title="inline ptx assembly in CUDA"></a>inline ptx assembly in CUDA</h1><p>asm()提供了一种将PTX代码插入CUDA的一种方法，形式为<br><figure class="highlight abnf"><table><tr><td class="code"><pre><span class="line">asm(<span class="string">&quot;membar.gl;&quot;</span>)<span class="comment">;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="parameters"><a href="#parameters" class="headerlink" title="parameters"></a>parameters</h2><p>asm的基本语法为<br><figure class="highlight lisp"><table><tr><td class="code"><pre><span class="line">asm(<span class="string">&quot;template-string&quot;</span> : <span class="string">&quot;constraint&quot;</span>(<span class="name">output</span>) : <span class="string">&quot;constraint&quot;</span>(<span class="name">input</span>))<span class="comment">;</span></span><br></pre></td></tr></table></figure><br>其中可以有多个’input’输入’output’输出，使用逗号隔开。’template-string’表示用于表明操作的PTX指令，多个ptx指令用分号隔开。</p>
<blockquote>
<p>通常一条指令包括两方面的内容： 操作码和操作数，操作码决定要完成的操作，操作数指参加运算的数据及其所在的单元地址。</p>
</blockquote>
<p>例如<br><figure class="highlight lisp"><table><tr><td class="code"><pre><span class="line">asm(<span class="string">&quot;add.s32 %0, %1, %2;&quot;</span> : <span class="string">&quot;=r&quot;</span>(<span class="name">i</span>):<span class="string">&quot;r&quot;</span>(<span class="name">j</span>),<span class="string">&quot;r&quot;</span>(<span class="name">k</span>))<span class="comment">;</span></span><br></pre></td></tr></table></figure><br>template-string中的每个%n表示后面的操作数的顺序，%0是第一个操作数，%1是第二个操作数以此类推。输出操作数总是在输入操作数的前面。这个例子等价于<br><figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">add<span class="selector-class">.s32</span> <span class="selector-tag">i</span>,j,k</span><br></pre></td></tr></table></figure><br>注意，string中的%n的顺序是可变的，上面的指令也可以写成<br><figure class="highlight lisp"><table><tr><td class="code"><pre><span class="line">asm(<span class="string">&quot;add.s32 %0, %2, %1;&quot;</span>:<span class="string">&quot;=r&quot;</span>(<span class="name">i</span>):<span class="string">&quot;r&quot;</span>(<span class="name">k</span>),<span class="string">&quot;r&quot;</span>(<span class="name">j</span>))<span class="comment">;</span></span><br></pre></td></tr></table></figure><br>%n也可以重复<br><figure class="highlight lisp"><table><tr><td class="code"><pre><span class="line">asm(<span class="string">&quot;add.s32 %0,%1,%1;&quot;</span>:<span class="string">&quot;=r&quot;</span>(<span class="name">i</span>):<span class="string">&quot;r&quot;</span>(<span class="name">k</span>))<span class="comment">;</span></span><br></pre></td></tr></table></figure><br>如果这里没有输入操作数，可以舍去最后的冒号<br><figure class="highlight lisp"><table><tr><td class="code"><pre><span class="line">asm(<span class="string">&quot;mov.s32 %0, 2;&quot;</span>:<span class="string">&quot;=r&quot;</span>(<span class="name">i</span>))<span class="comment">;</span></span><br></pre></td></tr></table></figure><br>如果这里没有输出操作数，可以连接两个冒号<br><figure class="highlight lisp"><table><tr><td class="code"><pre><span class="line">asm(<span class="string">&quot;mov.s32 r1, %0;&quot;</span>::<span class="string">&quot;r&quot;</span>(<span class="name">i</span>))<span class="comment">;</span></span><br></pre></td></tr></table></figure><br>如果想要在PTX中使用%，需要使用两个%来进行转义<br><figure class="highlight lisp"><table><tr><td class="code"><pre><span class="line">asm(<span class="string">&quot;mov.s32 %0, %%clock;&quot;</span>:<span class="string">&quot;=r&quot;</span>(<span class="name">x</span>))<span class="comment">;</span></span><br></pre></td></tr></table></figure><br>操作数值通过约束指定的任何机制传递。这里的<code>r</code>constraint表示32bit的整型寄存器<br><figure class="highlight lisp"><table><tr><td class="code"><pre><span class="line">asm(<span class="string">&quot;add.s32 %0,%1,%2;&quot;</span>:<span class="string">&quot;=r&quot;</span>(<span class="name">i</span>):<span class="string">&quot;r&quot;</span>(<span class="name">j</span>),<span class="string">&quot;r&quot;</span>(<span class="name">k</span>))<span class="comment">;</span></span><br></pre></td></tr></table></figure><br>会产生下列的代码（通过编译器生成）<br><figure class="highlight avrasm"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ld</span>.s32 <span class="built_in">r1</span>, [j]<span class="comment">;</span></span><br><span class="line"><span class="keyword">ld</span>.s32 <span class="built_in">r2</span>, [k]<span class="comment">;</span></span><br><span class="line"><span class="keyword">add</span>.s32 <span class="built_in">r3</span>, <span class="built_in">r1</span>, <span class="built_in">r2</span><span class="comment">;</span></span><br><span class="line"><span class="keyword">st</span>.s32 [i], <span class="built_in">r3</span></span><br></pre></td></tr></table></figure><br>输入操作数在asm语句之前加载到寄存器中，然后将结果寄存器存储到输出操作数中。”=r”中的”=”修饰符指定写入寄存器，还有”+”修饰符modifier指定寄存器是读和写，例如<br><figure class="highlight lisp"><table><tr><td class="code"><pre><span class="line">asm(<span class="string">&quot;add.s32 %0, %0, %1;&quot;</span>:<span class="string">&quot;+r&quot;</span>(<span class="name">i</span>):<span class="string">&quot;r&quot;</span>(<span class="name">j</span>))<span class="comment">;</span></span><br></pre></td></tr></table></figure><br>多个指令可以组合成一个asm（）语句;基本上，任何合法的东西都可以放入asm字符串中。通过使用 C/C++ 的隐式string串联，可以将多个指令拆分到多行中。C++样式行末尾注释“//”和经典的C样式注释“/**/”都可以穿插这些字符串用作注释。template-string要在 PTX 中间文件中生成可读输出，最佳做法是以”\n\t”终止每个指令字符串，但最后一个指令字符串除外。</p>
<p>例如，一个例程可以为<br><figure class="highlight wren"><table><tr><td class="code"><pre><span class="line"><span class="variable">__device__</span> int <span class="title function_">cube</span>(<span class="params">int</span> <span class="params">x</span>)</span><br><span class="line">&#123;</span><br><span class="line">    int <span class="variable">y</span>;</span><br><span class="line">    <span class="title function_">asm</span>(<span class="string">&quot;.reg .u32 t1;<span class="char escape_">\n</span><span class="char escape_">\t</span>&quot;</span> <span class="comment">// temp reg t1</span></span><br><span class="line">        <span class="string">&quot;mul.lo.u32 t1, %1, %1;<span class="char escape_">\n</span><span class="char escape_">\t</span>&quot;</span>    <span class="comment">//t1=x*x</span></span><br><span class="line">        <span class="string">&quot;mul.lo.u32 %0, t1, %1;&quot;</span>        <span class="comment">//y=t1*x</span></span><br><span class="line">        : <span class="string">&quot;=r&quot;</span>(<span class="variable">y</span>):<span class="string">&quot;r&quot;</span>(<span class="variable">x</span>));</span><br><span class="line">    <span class="keyword">return</span> <span class="variable">y</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>如果输出操作数由 asm 指令有条件地更新，则应使用“+”修饰符。在这种情况下，输出操作数是隐式使用的。例如<br><figure class="highlight wren"><table><tr><td class="code"><pre><span class="line"><span class="variable">__device__</span> int <span class="title function_">cond</span>(<span class="params">int</span> <span class="params">x</span>)</span><br><span class="line">&#123;</span><br><span class="line">    int <span class="variable">y</span><span class="operator">=</span><span class="number">0</span>;</span><br><span class="line">    <span class="title function_">asm</span>(<span class="string">&quot;&#123;<span class="char escape_">\n</span><span class="char escape_">\t</span>&quot;</span></span><br><span class="line">        <span class="string">&quot;.reg .pred %p;<span class="char escape_">\n</span><span class="char escape_">\t</span>&quot;</span></span><br><span class="line">        <span class="string">&quot;setp.eq.s32 %p,%1,34;<span class="char escape_">\n</span><span class="char escape_">\t</span>&quot;</span> <span class="comment">// x==34?</span></span><br><span class="line">        <span class="string">&quot;@%p mov.s32 %0, 1;<span class="char escape_">\n</span><span class="char escape_">\t</span>&quot;</span>    <span class="comment">// set y to 1 if true</span></span><br><span class="line">        <span class="string">&quot;&#125;&quot;</span>                         <span class="comment">// conceptually y=(x==34)?1:y</span></span><br><span class="line">        :<span class="string">&quot;+r&quot;</span>(<span class="variable">y</span>):<span class="string">&quot;r&quot;</span>(<span class="variable">x</span>));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="variable">y</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h2 id="constraint"><a href="#constraint" class="headerlink" title="constraint"></a>constraint</h2><p>每个 PTX 寄存器类型都有一个单独的约束符：<br><figure class="highlight abnf"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;h&quot;</span><span class="operator">=</span> .u16 reg</span><br><span class="line"><span class="string">&quot;r&quot;</span><span class="operator">=</span> .u32 reg</span><br><span class="line"><span class="string">&quot;l&quot;</span><span class="operator">=</span> .u64 reg</span><br><span class="line"><span class="string">&quot;f&quot;</span><span class="operator">=</span> .f32 reg</span><br><span class="line"><span class="string">&quot;d&quot;</span><span class="operator">=</span> .f64 reg</span><br></pre></td></tr></table></figure><br>约束“n”可用于具有已知值的即时整数操作数。<br>例如<br><figure class="highlight lisp"><table><tr><td class="code"><pre><span class="line">asm(<span class="string">&quot;cvt.f32.s64 %0,%1;&quot;</span>:<span class="string">&quot;=f&quot;</span>(<span class="name">x</span>):<span class="string">&quot;l&quot;</span>(<span class="name">y</span>))<span class="comment">;</span></span><br></pre></td></tr></table></figure><br>将会生成<br><figure class="highlight armasm"><table><tr><td class="code"><pre><span class="line"><span class="symbol">ld.s64</span> rdl,[y]<span class="comment">;</span></span><br><span class="line"><span class="symbol">cvt.f32.s64</span> <span class="built_in">f1</span>,rd1<span class="comment">;</span></span><br><span class="line"><span class="symbol">st.f32</span> [x],<span class="built_in">f1</span><span class="comment">;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="pitfalls"><a href="#pitfalls" class="headerlink" title="pitfalls"></a>pitfalls</h2><p>虽然 asm（） 语句非常灵活和强大，但你可能会遇到一些陷阱</p>
<h3 id="namespace-conflicts"><a href="#namespace-conflicts" class="headerlink" title="namespace conflicts"></a>namespace conflicts</h3><p>如果在程序中多次调用并内联cube function，则会对临时寄存器t1的重复定义。为了避免这个，需要</p>
<ul>
<li>不要内联cube function</li>
<li>在{}中使用’t1’，以便它对每个调用都有单独作用域，即<figure class="highlight wren"><table><tr><td class="code"><pre><span class="line"><span class="variable">__device__</span> int <span class="title function_">cube</span>(<span class="params">int</span> <span class="params">x</span>)</span><br><span class="line">&#123;</span><br><span class="line">    int <span class="variable">y</span>;</span><br><span class="line">    <span class="title function_">asm</span>(<span class="string">&quot;&#123;<span class="char escape_">\n</span><span class="char escape_">\t</span>&quot;</span>             <span class="comment">// use braces for scope</span></span><br><span class="line">        <span class="string">&quot;.reg .u32 t1;<span class="char escape_">\n</span><span class="char escape_">\t</span>&quot;</span> <span class="comment">// temp reg t1</span></span><br><span class="line">        <span class="string">&quot;mul.lo.u32 t1, %1, %1;<span class="char escape_">\n</span><span class="char escape_">\t</span>&quot;</span>    <span class="comment">//t1=x*x</span></span><br><span class="line">        <span class="string">&quot;mul.lo.u32 %0, t1, %1;&quot;</span>        <span class="comment">//y=t1*x</span></span><br><span class="line">        <span class="string">&quot;&#125;&quot;</span></span><br><span class="line">        : <span class="string">&quot;=r&quot;</span>(<span class="variable">y</span>):<span class="string">&quot;r&quot;</span>(<span class="variable">x</span>));</span><br><span class="line">    <span class="keyword">return</span> <span class="variable">y</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="memory-space-conflicts"><a href="#memory-space-conflicts" class="headerlink" title="memory space conflicts"></a>memory space conflicts</h3><p>由于 asm（） 语句无法知道寄存器所在的内存空间，因此用户必须确保使用适当的 PTX 指令。指向 asm（） 语句的任何指针参数都作为通用地址传递.</p>
<h4 id="incorrect-optimization"><a href="#incorrect-optimization" class="headerlink" title="incorrect optimization"></a>incorrect optimization</h4><p>编译器假定asm语句除了更改输出操作数之外没有任何作用。要确保在生成PTX期间不会删除或移动asm，应使用volatile关键字.<strong>volatile</strong>用于告诉编译器，严禁将此处的汇编语句与其它的语句重组合优化。即：原原本本按原来的样子处理这这里的汇编。<br><figure class="highlight llvm"><table><tr><td class="code"><pre><span class="line"><span class="keyword">asm</span> <span class="keyword">volatile</span>(<span class="string">&quot;mov.u32 %0, %%clock;&quot;</span>::<span class="string">&quot;=r&quot;</span>(<span class="keyword">x</span>))<span class="comment">;</span></span><br></pre></td></tr></table></figure><br>通常，写入的任何内存都将被指定为 out 操作数，但如果对用户内存有隐藏的副作用（例如，通过操作数间接访问内存位置），或者如果要停止在生成 PTX 期间围绕 asm（）语句执行的任何内存优化，则可以在第 3 个冒号后添加“memory”clobbers 规范，memory 强制 gcc 编译器假设 RAM 所有内存单元均被汇编指令修改，这样 cpu 中的 registers 和 cache 中已缓存的内存单元中的数据将作废。cpu 将不得不在需要的时候重新读取内存中的数据。这就阻止了 cpu 又将 registers, cache 中的数据用于去优化指令，而避免去访问内存。<br><figure class="highlight lisp"><table><tr><td class="code"><pre><span class="line">asm volatile(<span class="string">&quot;mov.u32 %0, %%clock;&quot;</span>: <span class="string">&quot;=r&quot;</span>(<span class="name">x</span>) :: <span class="string">&quot;memory&quot;</span>)<span class="comment">;</span></span><br><span class="line">asm (<span class="string">&quot;st.u32 [%0], %1;&quot;</span>: <span class="string">&quot;r&quot;</span>(<span class="name">p</span>), <span class="string">&quot;r&quot;</span>(<span class="name">x</span>) :: <span class="string">&quot;memory&quot;</span>)<span class="comment">;</span></span><br></pre></td></tr></table></figure></p>
<h3 id="incorrect-PTX"><a href="#incorrect-PTX" class="headerlink" title="incorrect PTX"></a>incorrect PTX</h3><p>编译器前端不解析asm语句模板字符串，也不知道他的含义甚至不确保ptx是否有效。例如<br><figure class="highlight lisp"><table><tr><td class="code"><pre><span class="line">asm(<span class="string">&quot;mov.u32 %0,%n1;&quot;</span>:<span class="string">&quot;=r&quot;</span>(<span class="name">n</span>):<span class="string">&quot;r&quot;</span>(<span class="number">1</span>))<span class="comment">;</span></span><br></pre></td></tr></table></figure><br>“%n1”中的“n”修饰符不受支持，它将传递给 ptxas，其中它可能导致未定义的行为。</p>
<h2 id="error-checking"><a href="#error-checking" class="headerlink" title="error checking"></a>error checking</h2><p>以下是编译器将在 inline PTX asm 上执行的一些错误检查</p>
<ul>
<li><p>不允许单个asm操作数只用多个constraint</p>
<figure class="highlight lisp"><table><tr><td class="code"><pre><span class="line">asm(<span class="string">&quot;add.s32 %0,%1,%2;&quot;</span>:<span class="string">&quot;=r&quot;</span>(<span class="name">i</span>):<span class="string">&quot;rf&quot;</span>(<span class="name">j</span>),<span class="string">&quot;r&quot;</span>(<span class="name">k</span>))<span class="comment">;</span></span><br></pre></td></tr></table></figure>
<p>错误：asm 操作数可能只在<strong>device</strong>/<strong>global</strong>函数中指定一个constraint字母</p>
</li>
<li><p>只允许标量变量作为asm操作数。特别是不允许使用struct类型变量</p>
<figure class="highlight lisp"><table><tr><td class="code"><pre><span class="line">int4 i4</span><br><span class="line">asm(<span class="string">&quot;add.s32 %0,%1,%2;&quot;</span>:<span class="string">&quot;=r&quot;</span>(<span class="name">i4</span>):<span class="string">&quot;r&quot;</span>(<span class="name">j</span>):<span class="string">&quot;r&quot;</span>(<span class="name">k</span>))<span class="comment">;</span></span><br></pre></td></tr></table></figure>
<p>错误：asm操作数必须是标量</p>
</li>
</ul>
<p>PTX中asm constraint所隐含的类型和大小必须与关联操作数的类型和大小匹配。例如其中ci是<code>char</code><br><figure class="highlight lisp"><table><tr><td class="code"><pre><span class="line">asm(<span class="string">&quot;add.s32 %0,%1,%2;&quot;</span>:<span class="string">&quot;=r&quot;</span>(<span class="name">ci</span>):<span class="string">&quot;r&quot;</span>(<span class="name">j</span>):<span class="string">&quot;r&quot;</span>(<span class="name">k</span>))<span class="comment">;</span></span><br></pre></td></tr></table></figure><br>错误：asm 操作数类型 size（1） 与约束 “r” 所暗示的类型/大小不匹配<br>为了在上面的 asm 语句中使用 “char” 类型变量 “ci”、“cj” 和 “ck”，可以使用类似于以下内容的代码段<br><figure class="highlight lisp"><table><tr><td class="code"><pre><span class="line">inttemp = ci<span class="comment">;</span></span><br><span class="line">asm(<span class="string">&quot;add.s32 %0,%1,%2;&quot;</span>:<span class="string">&quot;=r&quot;</span>(<span class="name">temp</span>):<span class="string">&quot;r&quot;</span>((<span class="name">int</span>)cj),<span class="string">&quot;r&quot;</span>((<span class="name">int</span>)ck))<span class="comment">;</span></span><br><span class="line">ci = temp<span class="comment">;</span></span><br></pre></td></tr></table></figure><br>类型不匹配的另一个示例：对于“float”类型变量“fi”，<br><figure class="highlight lisp"><table><tr><td class="code"><pre><span class="line">asm(<span class="string">&quot;add.s32 %0,%1,%2;&quot;</span>:<span class="string">&quot;=r&quot;</span>(<span class="name">fi</span>):<span class="string">&quot;r&quot;</span>(<span class="name">j</span>),<span class="string">&quot;r&quot;</span>(<span class="name">k</span>))<span class="comment">;</span></span><br></pre></td></tr></table></figure><br>错误：asm 操作数类型 size（4） 与约束 “r” 所隐含的类型/大小不匹配</p>
<h1 id=""><a href="#" class="headerlink" title=" "></a> </h1>]]></content>
      <categories>
        <category>cuda进阶学习</category>
      </categories>
      <tags>
        <tag>gpu</tag>
        <tag>ptx</tag>
      </tags>
  </entry>
  <entry>
    <title>非结构稀疏</title>
    <url>/2022/04/09/%E9%9D%9E%E7%BB%93%E6%9E%84%E7%A8%80%E7%96%8F/</url>
    <content><![CDATA[<h1 id="Deep-Neural-Networks"><a href="#Deep-Neural-Networks" class="headerlink" title="Deep Neural Networks"></a>Deep Neural Networks</h1><p><img src="https://raw.githubusercontent.com/HURONG0510/blogpic/main/20220409/微信截图_20220409221424.7c2prqkmli80.png" alt="神经网络简单举例"></p>
<p>ANN是一类执行分类、拟合和其它数据分析任务的模型。他们是由一系列的layer组成，每个layer在输入向量上执行线性或赋形变化，然后在生成的向量上应用非线性函数，称为激活函数。数据依次遍历这些层得到最终结果。执行其它功能的layer也可能出现在网络中，包含降低数据维度的pooling layer，提高网络对从未见过的数据性能的regularization layer。<br>神经网络中的数据和变化通常表示为tensor。网络在训练期间设置的值称为parameters或weights，将向网络呈现数据和更新参数的单一步骤称为一个training iteration。对所有训练数据集执行示例过程，直到网络得到充分训练，每次对整个训练数据集进行网络训练时，都被称为一个epoch。一个神经网络通常被训练上十或上百次。在训练过程中控制网络训练或操作但未被修改的值被称为hyperparameters.一旦网络被训练完成，参数就固定，模型可以用来分析新数据，这个过程称为inference。</p>
<p>最简单的神经网络layer是dense或fully-connected layer。密集层输入长度为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0" xmlns="http://www.w3.org/2000/svg" width="2.009ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 888 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g></g></g></svg></mjx-container>的向量<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex" xmlns="http://www.w3.org/2000/svg" width="1.294ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 572 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></svg></mjx-container>,产生长度为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0" xmlns="http://www.w3.org/2000/svg" width="2.378ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 1051 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g></g></g></svg></mjx-container>的向量<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex" xmlns="http://www.w3.org/2000/svg" width="1.109ex" height="1.464ex" role="img" focusable="false" viewBox="0 -442 490 647"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container>，其参数由权重矩阵<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.09ex" xmlns="http://www.w3.org/2000/svg" width="11.389ex" height="2.004ex" role="img" focusable="false" viewBox="0 -846 5033.8 886"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mo" transform="translate(1325.8,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="msup" transform="translate(2270.6,0)"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g><g data-mml-node="mo" transform="translate(1051,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(1829,0)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g></g></g></g></g></svg></mjx-container>，他的实现函数为<script type="math/tex">y=f(Wx+b)</script>其中<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex" xmlns="http://www.w3.org/2000/svg" width="3.005ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 1328 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mo" transform="translate(550,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mo" transform="translate(939,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>是activation function。深度神经网络在输入和输出之间具有许多层，使它们能够学习非常复杂的函数，并减少或消除对特征提取的需求。与其他统计模型相比，DNN 具有非常多的参数，通常从数十万到数亿个参数不等。</p>
<p>现代DNN在根据其训练数据进行评估时通常可以达到非常高的准确性，但在未知数据集上获得类似性能可能会很大难度。已经开发了很多方法来改善未知数据集的模型性能，有时以降低训练数据的性能为代价，这些方法称为regularization。它们包括对训练过程的修改、对优化器目标的修改以及神经网络中的其他层，例如 dropout和batch normalization层。 </p>
<h1 id="Neural-Network-Pruning"><a href="#Neural-Network-Pruning" class="headerlink" title="Neural Network Pruning"></a>Neural Network Pruning</h1><p>DNN中的大量参数使他们在实践中难以应用。neural network pruning属于最后一类。修剪方法是用于训练神经网络或调整已经训练过的网络的技术，以便其大量参数变为零。这样做的方式是尽量减少修剪导致的推理准确性的降低。如果我们将每个参数视为表示线性变换中输入和输出之间的连接，则可以将修剪视为删除这些连接。如下所示，pruning fraction或pruning rate是图层或网络中被修剪的connected fraction。<br><img src="https://raw.githubusercontent.com/HURONG0510/blogpic/main/20220409/微信截图_20220409234507.1phl2u16wtuo.png" alt=""><br>使用修剪来加速推理时，一个重要的问题是，所讨论的硬件是否可以实际利用修剪的表示形式。通常需要强加某种结构来管理可以修剪哪些连接，以便看到显着的改进。例如，这可能意味着删除权重矩阵的整行，而不是矩阵的任意元素。以需要遵循特定结构的方式修剪称为结构化修剪，而没有结构要求的修剪称为非结构化修剪。 使用结构化而不是非结构化修剪会带来权衡。粗略地说，结构越严格，可以删除的连接就越少，而不会严重损害网络的准确性。这是因为非结构化修剪可以更自由地删除那些对网络性能损害最小的权重。在实践中，决定是否使用结构化修剪以及如果是，要施加什么结构要求取决于特定应用程序的要求以及用于推理的硬件。</p>
<h1 id="GPU设计准则"><a href="#GPU设计准则" class="headerlink" title="GPU设计准则"></a>GPU设计准则</h1><p>参考了文章</p>
<h2 id="latency-hiding-with-TLP-and-ILP"><a href="#latency-hiding-with-TLP-and-ILP" class="headerlink" title="latency hiding with TLP and ILP"></a>latency hiding with TLP and ILP</h2><p>如果 GPU 上驻留了足够的warp（如果我们有足够的 TLP），则在warp之间切换可以完全隐藏长延时操作的成本。我们将程序中的 TLP 数量量化为占用率occupancy，即可用（发出的）warp与 GPU 可支持的最大warp数之比。更高的占用率产生更好的延迟隐藏能力，这使我们能够实现充分利用。<br>另一种延迟隐藏策略是利用指令级并行性（ILP）及其利用单个线程中多个内存操作的延迟重叠的能力。由于 GPU 的内存系统是深度流水线的，因此线程在变为非活动状态之前可能会发出多个独立的长延迟操作，并且这些多个操作将共同产生与单个操作大致相同的延迟。虽然这产生了显著的性能优势，但它依赖于程序员向硬件公开独立的内存操作。我们可以通过将多个独立任务分配给同一线程（“线程粗化”）来实现此目标。</p>
<p>GPU 具有固定数量的寄存器。TLP 需要许多驻留warp，每个warp都需要寄存器。ILP 会增加每个线程的工作，因此每个线程需要更多的寄存器。因此，TLP和ILP是对立的，要充分利用这两种技术，就需要仔细平衡这两种技术。虽然TLP通常用于所有GPU计算，但ILP是一个较少探索的领域。</p>
<h2 id="load-balancing"><a href="#load-balancing" class="headerlink" title="load-balancing"></a>load-balancing</h2><p>我们现在转向的问题是，确保所有计算单元在每个周期上都做有用的工作，并且从这些warp访问的内存被合并以确保峰值内存性能。在SpMV和SpMM的content中，这种“负载平衡”问题有两个方面：</p>
<ol>
<li>warp之间的负载不均。某些 CTA(block) 或 warp 分配的工作量可能比其他 CTA 或 warp 少，这可能导致这些负载较少的计算单元处于空闲状态，而负载较多的计算单元继续执行有用的工作。在本文中，我们称之为“Type 1”负载不平衡。 </li>
<li>warp内部的负载不均。在两个方面，我们统称为“Type 2”负载不平衡。<br>(a) 某些warp可能没有足够的work来占用warp中的所有32个线程。在这种情况下，线程单元处于空闲状态，我们会损失性能。<br>(b) 某些warp可能会将不同的任务分配给不同的线程。 在这种情况下，线程内的 SIMT 执行意味着某些线程处于空闲状态，而其他线程正在运行;此外，执行过程中的warp分化意味着整个warp中的内存访问不太可能合并。</li>
</ol>
]]></content>
      <categories>
        <category>矩阵计算</category>
      </categories>
      <tags>
        <tag>gpu</tag>
        <tag>matrix</tag>
      </tags>
  </entry>
  <entry>
    <title>warp function</title>
    <url>/2022/04/08/warp-function/</url>
    <content><![CDATA[<p>以下是关于warp function的一些理解<br>主要参考资料是nVidia的官方文档</p>
<h1 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h1><p>warp的概念不加赘述，且建议在<strong>capability 7.x以上且cuda9.0以上</strong>的GPU上测试，有些函数在例如 <strong>any, </strong>all, and __ballot等在cuda9.0上已经被移除。</p>
<blockquote>
<p>predicate表示线程的一种状况<br>以下所有的实例，使用一个block，block块的大小是32，所说的线程号就是laneID<br>mask中的第i个bit表示第i个线程</p>
</blockquote>
<h1 id="warp-vote-functions"><a href="#warp-vote-functions" class="headerlink" title="warp vote functions"></a>warp vote functions</h1><ul>
<li>允许给定warp中的线程执行规约和广播操作</li>
<li>所有线程的lane的mask必须一致</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> __all_sync(<span class="type">unsigned</span> mask, <span class="type">int</span> predicate);</span><br><span class="line"><span class="type">int</span> __any_sync(<span class="type">unsigned</span> mask, <span class="type">int</span> predicate);</span><br><span class="line"><span class="type">unsigned</span> __ballot_sync(<span class="type">unsigned</span> mask, <span class="type">int</span> predicate);</span><br><span class="line"><span class="type">unsigned</span> __activemask()</span><br></pre></td></tr></table></figure>
<p><code>__all_sync</code> 评估<code>mask</code>中所有non-exited的线程（线程对应mask的位是1）的predicate，返回非零值当且仅当mask中对应线程的predicate都是非零的。</p>
<p><code>__any_sync</code> 评估<code>mask</code>中所有non-exited的线程（线程对应mask的位是1）的predicate，返回非零值当且仅当mask中对应线程的predicate存在非零的。</p>
<p><code>_ballot_sync</code>评估<code>mask</code>中所有non-exited线程的predicate，返回一个unsigned数，其第N位为1当且仅当<code>mask</code>中线程的predicate非零</p>
<p><code>__activemask()</code> 返回unsigned数 <code>mask</code>，表示这个warp中所有的active状态的线程</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">wall</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> laneId=threadIdx.x &amp; <span class="number">0x1f</span>;</span><br><span class="line">    <span class="type">int</span> predicate= laneId%<span class="number">2</span>;</span><br><span class="line">    <span class="type">unsigned</span> n;</span><br><span class="line">    n=__all_sync(<span class="number">0x55555555</span>,predicate);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Thread %d final n= %x\n&quot;</span>, threadIdx.x, n);</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>0x55555555</code>表示所有偶数位是1，奇数位是0。<code>predicate</code>是所有的偶数线程是0，奇数线程是1。在<code>__all_sync</code>下，所有线程的n是0，因为其只统计mask中non-exited的线程，<code>0x55555555</code>使得<code>__all_sync</code>只检查偶数位的线程，结果偶数位线程的predicate都是0。其余函数同理。</p>
<h1 id="warp-match-functions"><a href="#warp-match-functions" class="headerlink" title="warp match functions"></a>warp match functions</h1><ul>
<li>执行warp内线程之间变量的广播和比较操作</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">unsigned</span> <span class="type">int</span> __match_any_sync(<span class="type">unsigned</span> mask, T value);</span><br><span class="line"><span class="type">unsigned</span> <span class="type">int</span> __match_all_sync(<span class="type">unsigned</span>  mask, T value, <span class="type">int</span> *pred)</span><br><span class="line"><span class="comment">//T可以是int/unsigned int/long/unsigned long/long long/unsigned long long/float/double</span></span><br></pre></td></tr></table></figure>
<h1 id="warp-shuffle-function"><a href="#warp-shuffle-function" class="headerlink" title="warp shuffle function"></a>warp shuffle function</h1><ul>
<li>交换warp内部的线程的值</li>
<li>采用可选的width，必须是2的幂次，且不能大于warpsize</li>
<li>mask的值没有影响，不管mask是什么，结果都一致<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">T __shfl_sync(<span class="type">unsigned</span> mask, T var, <span class="type">int</span> srcLane, <span class="type">int</span> width=warpSize);</span><br><span class="line">T __shfl_up_sync(<span class="type">unsigned</span> mask, T var, <span class="type">unsigned</span> <span class="type">int</span> delta, <span class="type">int</span> width=warpSize);</span><br><span class="line">T __shfl_down_sync(<span class="type">unsigned</span> mask, T var, <span class="type">unsigned</span> <span class="type">int</span> delta, <span class="type">int</span> width=warpSize);</span><br><span class="line">T __shfl_xor_sync(<span class="type">unsigned</span> mask, T var, <span class="type">int</span> laneMask, <span class="type">int</span> width=warpSize);</span><br><span class="line"></span><br><span class="line"><span class="comment">//T can be int, unsigned int, long, unsigned long, long long, unsigned long long, float or double. With the cuda_fp16.h header included, T can also be __halfor __half2. Similarly, with the cuda_bf16.h header included, T can also be __nv_bfloat16 or __nv_bfloat162.</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<code>__shfl_sync()</code>返回srclane号线程的var，<code>width</code>将warpsize的线程数进行划分，每个子段长度为<code>width</code>。每个<code>width</code>中的线程得到<code>srclane</code>所指示的<code>var</code>，注意这里<code>srclane</code>都是<code>width</code>中的相对位置。<br>若是每个线程的<code>var</code>是它本身的线程值，那么<blockquote>
<p><code>__shfl_sync(mask,threadIdx.x,0,4)</code>，得到的结果是 4x0, 4x4, 4x8, 4x12, 4x16, 4x20, 4x24, 4x28, 4x32<br><code>__shfl_sync(mask,x,2,8)</code>, 得到的结果是2x8, 10x8, 18x8, 26x8</p>
</blockquote>
</li>
</ul>
<p><code>_shfl_up_sync()</code> 返回向前偏移为 <code>delta</code> 的线程中的变量 <code>var</code> 的值，其余线程返回0。<code>width</code>将warpsize划分成warpsize/width个部分，每个部分返回的是当前的线程-delta的线程的value，若是减法结果为-，那么结果就不会变。注意这里是相对值，记得上面这个减法必须是要一个分组内。</p>
<blockquote>
<p>例如<code>n=__shfl_up_sync(0xffffffff,value,15,16);</code><br>结果是0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 0 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 16</p>
</blockquote>
<p><code>__shfl_down_sync()</code> 线程返回向后偏移为 delta 的线程中的变量 var 的值，其余线程返回0 。</p>
<blockquote>
<p>调用 <code>__shfl_down_sync(mask, x, 2, 16)</code>; 则标号为 0-13 的线程分别获得标号为 2-15 的线程中变量 x 的值；标号为 16 -29 的线程分别获得标号为 18 - 31 的线程中变量 x 的值。</p>
</blockquote>
<p><code>__shfl_xor_sync()</code>通过对调用者的通道ID与<code>laneMask</code>进行按位异或（XOR）运算来计算源通道ID。返回值为计算所得源通道中的var值。此模式实现了蝶形寻址模式。如果<code>width</code>小于warpsize，那么对于异或的结果，若是处于前面的group，那么可以获取异或的结果，若是处于后面的group，则会返回本身的var</p>
<blockquote>
<p>例如<code>n=__shfl_xor_sync(0,threadIdx.x,3,4);</code>的结果是3 2 1 0 7 6 5 4 11 10 9 8 15 14 13 12 19 18 17 16 23 22 21 27 26 25 24 31 30 29 28<br>例如<code>n=__shfl_xor_sync(0,threadIdx.x,3,2);</code>的结果是0 1 1 0 4 5 5 4 8 9 9 8 12 13 13 12 16 17 17 16 20 21 21 20 24 25 25 24 28 29 29 28</p>
</blockquote>
]]></content>
      <categories>
        <category>cuda基础学习</category>
      </categories>
      <tags>
        <tag>cuda</tag>
        <tag>gpu</tag>
      </tags>
  </entry>
</search>
